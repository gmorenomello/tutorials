{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "domain_size = 10\n",
    "x_train = np.arange(domain_size,dtype=np.float64)+32\n",
    "x_train[-1] = 55 # outlier\n",
    "#x_train = np.reshape(x_train, (domain_size,1))\n",
    "y_train = np.zeros(x_train.shape)\n",
    "y_train[x_train >= 37] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4XOWZ/vHvM+qS5Sp3W+4NjKswhGqqCyGQhIQaQgJxNglhkw35kbDZhM1iQi8hNNNTFkK6E1cMGNMMtrExYMm9yb2rt5nn98cMWllItmw0Oir357p0ec6c9515dDyje+a857zH3B0RERGAUNAFiIhI86FQEBGRagoFERGpplAQEZFqCgUREammUBARkWoKBRERqaZQEBGRagoFERGplhh0AccqKyvL+/fvH3QZIiItyrJly/a6e9ejtWtxodC/f3+WLl0adBkiIi2KmW1uSLu47T4ys2fMbLeZfXSUdiebWdjMLotXLSIi0jDxHFN4Dph8pAZmlgDcBcyLYx0iItJAcQsFd18E7D9Ks+8DfwF2x6sOERFpuMCOPjKz3sAXgccb0HaamS01s6V79uyJf3EiIm1UkIekPgjc4u7hozV09xnunuPuOV27HnXwXEREjlOQRx/lAC+aGUAWMNXMqtz97wHWJCLSpgUWCu4+4JPbZvYc8C8FgohIsOIWCmb2AjARyDKzfOAXQBKAux91HEFEpC2rqIrwh3c3M6RbJmcMyWqy541bKLj7lcfQ9rp41SEi0pK4O/M+3sVdc/PYuLeYa07Nbh2hICIix+aDrQeZPiuX9zbtZ3C3djxzXQ7nDOvWpDUoFEREApZ/oIR75q3mHyu20yUjmdsvHckVJ/clMaHpDxBVKIiIBKSgrJLHFq7n6Tc3YsB3Jw7iOxMHkZmaFFhNCgURkSZWFY7wwntbeHDBWvYVV/DFsb25edIwendMC7o0hYKISFNxd17N280ds3NZv6eYCQM68+xFIxjVp2PQpVVTKIiINIGPth3ijtm5vL1+HwOzMpjxtfFccEJ3YifwNhsKBRGRONp5qIx75q3mr8vz6ZiWxG0Xn8DVp/YjKYBB5IZQKIiIxEFxeRVPvL6eGW9sIBKBaWcO5LvnDKZDWnCDyA2hUBARaUThiPPS0q3cN38Ne4vK+fyontwyeTh9O6cHXVqDKBRERBrJwtW7+dXsPFbvKmR8v07MuHY847I7BV3WMVEoiIh8Rnk7C5g+K5c31u4lu3M6j149jikjezS7QeSGUCiIiByn3QVl3P/yGl5aupXM1CR+dtEIvva5fqQkJgRd2nFTKIiIHKOSiiqeXLSRJxatpzIc4brTBnDTeYPpmJ4cdGmfmUJBRKSBwhHnr+/nc+/81ewqKGfKyB7cMnk4/bMygi6t0SgUREQa4K11e5k+K5dVOwoY3bcjv7lqHCf37xx0WY1OoSAicgTrdhdyx+w8Xs3bTe+OaTx0xRguHtWLUKjlDSI3hEJBRKQOe4vKeXDBGl54byvpSQn8ZMpwrjutP6lJLXcQuSEUCiIiNZRVhnn6zY08tnA9pZVhrj4lm38/bwhd2qUEXVqTUCiIiACRiPOPD7Zxz9zVbD9UxvkjuvPTqcMZ1LVd0KU1qbiFgpk9A3we2O3uI+tYfzVwS2yxCPiOu38Qr3pEROrz7oZ9TJ+dy8r8Q4zs3Z77vjqGzw3qEnRZgYjnN4XngN8Av61n/UbgbHc/YGZTgBnAKXGsR0TkMBv2FHHnnDzmr9pFzw6p3P/V0Vw6pnerHURuiLiFgrsvMrP+R1j/do3FxUCfeNUiIlLT/uIKfv3KWn6/eDMpiSFuvnAo158xkLTk1j2I3BDNZUzhemBO0EWISOtWXhXm+bc38fCr6ygur+KKCdn88PyhdM1sG4PIDRF4KJjZOURD4YwjtJkGTAPIzs5uospEpLVwd/61cgd3zc0j/0ApE4d15dapIxjaPTPo0pqdQEPBzEYBTwFT3H1ffe3cfQbRMQdycnK8icoTkVZg2eb93D4rl+VbDjK8Rya/u34CZw7pGnRZzVZgoWBm2cBfga+5+5qg6hCR1mnzvmLumpvH7A930i0zhbu/PIovj+9DQhseRG6IeB6S+gIwEcgys3zgF0ASgLs/Dvwc6AI8GptzvMrdc+JVj4i0DYdKKnn41bU8/84mEkMhfnD+EL515kAyUgLfW94ixPPooyuPsv4G4IZ4Pb+ItC0VVRF+t3gzv35lLQVllXxlfB9+dOEwurdPDbq0FkXRKSItmrsz7+Od3Dknj037SjhzSBa3Th3BiJ7tgy6tRVIoiEiLtWLrQabPWsWSTQcY0q0dz37jZCYO7doiL4PZXCgURKTFyT9Qwt1zVzPzg+1ktUtm+hdHcnlOXxITQkGX1uIpFESkxSgoq+TR19bzzFsbMeDGcwbzbxMH0U6DyI1GW1JEmr3KcIQX3tvCgwvWsr+4gi+N7c3Nk4bRq2Na0KW1OgoFEWm23J0Fubv51ZxcNuwp5tSBnfnZRScwsneHoEtrtRQKItIsfbTtELfPWsXiDfsZ2DWDp67N4bwR3TSIHGcKBRFpVrYfLOXeeav56/JtdM5I5peXnMiVE7JJ0iByk1AoiEizUFRexeML1/PkGxtw4NtnD+R75wymfWpS0KW1KQoFEQlUVTjCS0vzuf/lNewtKucLo3vx40nD6Ns5PejS2iSFgogEwt1ZuGYPv5qdy5pdReT068ST145nbHanoEtr0xQKItLkcncUcMfsXN5Yu5d+XdJ5/JpxTDqxhwaRmwGFgog0mV0FZdw/fw0vLdtK+9Qk/uvzJ/C1U/uRnKhB5OZCoSAicVdSUcWMRRt44vUNVEUiXH/6AL5/7hA6pGsQublRKIhI3IQjzl+W5XPv/NXsLixn6kk9uGXycPp1yQi6NKmHQkFE4uLNtXu5fdYq8nYWMja7I49dM47x/ToHXZYchUJBRBrVml2F3DE7l4Wr99CnUxoPXzmWz4/qqUHkFkKhICKNYk9hOQ8sWMOL720hIyWRW6cO59rP9Sc1KSHo0uQYKBRE5DMpqwzz9JsbefS1dZRXRbj2c/256bwhdM5IDro0OQ4KBRE5LpGI8/cV27hn3mp2HCrjghO689MpwxnYtV3QpclnELdQMLNngM8Du919ZB3rDXgImAqUANe5+/vxqkei3J1lO7bz+uaNFFZUcEJWV84bOIguafVPKRCJOCvWb+OdjzdTXFbBiOxunDFqIJ3a1T+XfSTifJCXz3sfbKakrILhg7pz+riBtD9CH/cwFeWLqShfhHsJiUljSE07j1Co42f6naXxLd6wj+mzcvlw2yFO6t2BBy4fw6kDuwRdVqsRiRyitGwBFRXLMUsnNeVMUlJOwyz+u+LiecbIc8DkI6yfAgyJ/UwDHotjLRLzysb1/OGjDyipqiQ9KYllO7bzmyWLKSgvq7fPayvW8ZdFH1JWUUVqciLvr9vGM7Pfpai0vP4+765h5isfUl5ZRUpKIss/zuf5v75LcWlFvX3KSmdSWvICES8HS6Wy/C2KCh8mEin5TL+zNJ71e4q44fmlXDFjMfuKynnw8jH843unKxAaUSRSQkHhw5SVvYFZGu4VFJf8kZKSvzXJ88ctFNx9EbD/CE0uAX7rUYuBjmbWM171CJRUVrJg4wZ6Z2aSmZxCckICPTMzKSqv4L3t2+rsU1xWwVsfbaRnl/ZkpCWTnJRI906ZFJSU88H67XX2KSopZ/GKjfTo1p70WJ9uWZkcKirj4zV194lEDlJevohQQl9CoXaYpRBK7IWH91FZsbzRtoEcn31F5fziHx8x6YFFLN6wjx9PGsarN0/k0rG9CYV0VFFjqqj4gHB4D4mJfaLvg1A7EhKyKSt/k3D4SH9SG0eQYwq9ga01lvNj9+0IppzWb39pKRF3EkOHfwXNSE5m88EDdfY5UFiCO5+6IHpaShL5ew7V3edQCQYkhA7vk5qSyLbddfeJhPdg2Ke/Hlsq4fBm4PT6fzGJm7LKMM+9vYlHXl1HSWWYKyf05QfnDyWrXUrQpbVaVeEtmKUedp9ZCCNEJLKHhIT4nusRZCjU9fHC62xoNo3oLiays7PjWVOr1iE1+kYORyKH/cEuqaykZ2b7Ovu0T0/F3YlE/LBPhOUVVXTrWPeAYvt2qUQcIu6ErFafLnX3sVAn3CO4+2HHszvlhBL0BbKpuTv/XLmDu+bkse1gKecO78ZPpwxnSPfMoEtr9RISeuAcvmvW3XGLEArFfwbZIGehygf61ljuA9S5b8HdZ7h7jrvndO3atUmKa40yk1M4tXcf8gsLqAiHcXf2l5aQFAoxoVefOvu0z0hl7JDe7Nh3iMqqWJ/CEhITQowZ0rvOPh0y0zhpWC927i6o7nPgUAnJSYmcNLRXnX0SErJITh5DJLwV98poEIX3YJZOcvK4RtsGcnRLN+3n0kff5qYXltM+LYk/3HAKz1x3sgKhiaQkj8Usg3B4d+yDUiXh8FaSk0aRkNAt7s8f5DeFmcCNZvYicApwyN216yjOLh46nHbJySzasomyqioGdurMF4YOJyu9/qOPpp46gnbpKSxetZmKyjD9enRi8snDj3j00dSzTyQzI5UlKzdRWRVhQJ/OnH/a8CMefZSWcSUW6kxF+Ru4V5KYNIy09EsJhXSR9qaweV8xd87JY85HO+nePoV7LhvFl8b1IUFjBk0qFGpPh8zvU1zydyorczFLJjX1XNLTjnTcTuMx9zr32Hz2BzZ7AZgIZAG7gF8ASQDu/njskNTfED1CqQT4hrsvPdrj5uTk+NKlR20mRxFxpyoSITmh4Ye4RSJOOBIhKbHhfcKRCJGIH1Mf9zAQxkwnPzWFgyUV/PqVdfxu8SaSEkJ8+6xBfOusAaQn6zSmoLlXAqFGORTVzJa5e87R2sXtf93drzzKege+F6/nlyMLmR1TIACEQkYodGx9EkIhjvV669E3gKZGiLeKqgi/fWcTD7+6jsKySr6a05f/uGAo3dqnHrWvNA2zpp9aXB8FRNoYd2fuRzu5c24em/eVcOaQLP7zohEM71H3wQbStigURNqQ5VsOMH1WLks3H2BY90ye/+YEzh6qgzfk/ygURNqArftLuGtuHv9auYOsdin86ksn8ZXxfT51/omIQkGkFTtUWsmjr63j2bc2EQrBTecOZtrZg2iXore+1E2vDJFWqDIc4Q+LN/PQK2s5WFrJl8b24eZJQ+nZof5DgkVAoSDSqrg7L6/axZ1z8tiwt5jTBnXh1qkjGNlb53pIwygURFqJD/MPcfusVby7cT+Dumbw9NdzOHd4N10GU46JQkGkhdt+sJR75q3mb8u30SUjmf+5dCRXnNyXJA0iy3FQKIi0UEXlVTy2cB1PvbERB74zcRDfmTiI9qlNf8KTtB4KBZEWpioc4cUlW3lwwRr2FlVw6Zhe3DxpGH061T9/lUhDKRREWgh357XVu7ljdh7rdhcxoX9nnv76CEb31eVKpfEoFERagFXbC5g+exVvrdtH/y7pPH7NeCad2F2DyNLoFAoizdiugjLunbeaP7+fT4e0JH5x8QlcfUo/khM1iCzxoVAQaYaKy6t4YtEGnly0gXDE+daZA/nexMF0SNcgssSXQkGkGQlHnD8v28p989ewu7Cci0b15JZJw8nuokFkaRoKBZFm4o21e5g+K5e8nYWMy+7IY9eMZ3y/+F+TV6QmhYJIwNbsKmT6rFxeX7OHvp3TeOSqcUw9qYcGkSUQCgWRgOwpLOf+l9fwxyVbaJeSyH9OHcG1p/Uj5RguXSrS2BQKIk2stCLMU29s4PHX11NeFeHrp/XnpnOH0ClD16SW4MU1FMxsMvAQ0QvuPuXud9Zanw08D3SMtfmJu8+OZ00iQYlEnL8u38a981azs6CMSSd25ydTRjAgKyPo0kSqxS0ULHr19UeAC4B8YImZzXT3VTWa/Qx4yd0fM7MTgNlA/3jVJBKUt9fvZfqsXD7eXsDoPh349ZVjmTCgc9BliXxKPL8pTADWufsGADN7EbgEqBkKDnxytfAOwPY41iPS5NbtLuLOObksyN1N745pPHTFGC4e1YtQSIPI0jzFMxR6A1trLOcDp9Rqcxsw38y+D2QA58exHpEms6+onAcXrOV/39tCelICt0wezjdO709qkgaRpXmLZyjU9VHIay1fCTzn7veZ2eeA35nZSHePHPZAZtOAaQDZ2dlxKVakMZRVhnn2rU08+to6SirDXDUhmx+cP4Qu7VKCLk2kQeIZCvlA3xrLffj07qHrgckA7v6OmaUCWcDumo3cfQYwAyAnJ6d2sIgELhJx/rlyO3fPXc22g6WcP6IbP5kynMHdMoMuTeSYxDMUlgBDzGwAsA24AriqVpstwHnAc2Y2AkgF9sSxJpFGt2TTfm7/1yo+yD/Eib3ac89lozhtcFbQZYkcl7iFgrtXmdmNwDyih5s+4+4fm9kvgaXuPhP4EfCkmf2Q6K6l69xd3wSkRdi4t5i75uQx9+Od9Gifyr1fGc2XxvbWILK0aHE9TyF2zsHsWvf9vMbtVcDp8axBpLEdKK7g16+u5XfvbCY5McSPLhjKDWcOJC1Zg8jS8umMZpEGKq8K89u3N/Pwq2spKq/i8pOz+eEFQ+iWmRp0aSKN5qihYGYhYKW7j2yCekSaHXdn9oc7uWtuHlv2l3D20K7cOnUEw3poEFlan6OGgrtHzOwDM8t29y1NUZRIc7Fs8wGmz1rF+1sOMrxHJr/95gTOGto16LJE4qahu496Ah+b2XtA8Sd3uvsX4lKVSMC27i/hzrl5zFq5g66ZKdz15ZO4bHxfEjSILK1cQ0Phv+NahUgzcai0kkdeW8dzb20iFIKbzhvCt88aSEaKht+kbWjQK93dXzezfsAQd19gZulEDzMVaRUqwxF+v3gzD72ylkOllVw2rg8/unAYPTpoEFnalgaFgpl9i+g0E52BQUTnNXqc6IlnIi2WuzN/1S7unJPHxr3FnD64C7dOHcGJvToEXZpIIBr6nfh7RGc9fRfA3deaWbe4VSXSBFbmH+T2Wbm8t3E/g7u149nrTmbisK66DKa0aQ0NhXJ3r/jkzWJmiXx6cjuRFmHbwVLumZvH31dsp0tGMrdfOpIrTu5LYkIo6NJEAtfQUHjdzG4F0szsAuC7wD/jV5ZI4yssq+TRhet5+s2NGPC9cwbxb2cPIjM1KejSRJqNhobCT4jOaPoh8G2iU1c8Fa+iRBpTVTjCC0u28uDLa9hXXMEXx/bm5knD6N0xLejSRJqdhobCJcBv3f3JeBYj0pjcnVfzdnPH7FzW7ylmwoDOPHvRCEb16Rh0aSLNVkND4QvAg2a2CHgRmOfuVfErS+Sz+Xj7IabPyuXt9fsYmJXBjK+N54ITumsQWeQoGnqewjfMLAmYQvSaCI+a2cvufkNcqxM5RjsPlXHv/NX85f18OqYlcdvFJ3D1qf1I0iCySIM0+DRNd680szlEjzpKI7pLSaEgzUJxeRVPvL6eGW9sIBKBaWcO5LvnDKZDmgaRRY5FQ09em0z0ymnnAAuJDjJ/NX5liTRMOOL8aelW7nt5DXsKy7l4dC/+36Rh9O2cHnRpIi1SQ78pXEd0LOHb7l4ev3JEGu71NXu4Y1Yuq3cVMr5fJ2Z8bTxjszsFXZZIi9bQMYUrYnMfnQksMLM0INHdC+NanUgd8nYWcMfsPBat2UN253QevXocU0b20CCySCM43rmP+qC5j6SJ7S4s4/75a3hp6VYyU5P42UUj+Nrn+pGSqLkZRRqL5j6SZq+0IsyTb2zg8dfXUxmOcN1pA7jpvMF0TE8OujSRVieucx/FBqgfIjrN9lPufmcdbb4K3BZ7vA/c/aoG1iStXCTi/OX9fO6dv5pdBeVMGdmDWyYPp39WRtClibRacZv7yMwSgEeAC4B8YImZzXT3VTXaDAF+Cpzu7gf07UM+8fa6vdw+K5dVOwoY3bcjv7lqHCf37xx0WSKtXjznPpoArHP3DQBm9iLRcxtW1WjzLeARdz8A4O67G166tEbrdhfyq9l5vJK3m94d0/j1lWP5/Ek9CekymCJN4oihYGbZ7r7F3SPAk7GfhuoNbK2xnA+cUqvN0NjzvEV0F9Nt7j73GJ5DWom9ReU8uGANL7y3lfSkBH4yZTjXndaf1CQNIos0paN9U/g7MA7AzP7i7l8+hseu66Nd7XGIRGAIMJHoEU1vmNlIdz942AOZTSN69BPZ2dnHUII0d2WVYZ5+cyOPLVxPaWWYa07J5t/PH0rnDA0iiwThaKFQ8w/7wGN87Hygb43lPsD2OtosdvdKYKOZrSYaEktqNnL3GcAMgJycHF3cpxWIRJyZH2znnnmr2XawlPNHdOenU4czqGu7oEsTadOOFgpez+2GWAIMMbMBwDai02TUPrLo78CVwHNmlkV0d9KGY3weaWHe3bCP6bNzWZl/iJG923PvV0bzuUFdgi5LRDh6KIw2swKi3xjSYreJLbu7t6+vo7tXmdmNwDyi4wXPuPvHZvZLYKm7z4ytu9DMVgFh4Mfuvu8z/k7STG3YU8Sdc/KYv2oXPTukcv9XR3PpmN4aRBZpRsy9Ze2NycnJ8aVLlwZdhhyD/cUV/PqVtfx+8WZSEkN895zBXH/GAA0iizQhM1vm7jlHa9fgqbNFjlV5VZjn397Ew6+uo7i8iismZPPD84fSNTMl6NJEpB4KBWl07s6/Vu7grrl55B8oZeKwrtw6dQRDu2cGXZqIHIVCQRrVss37uX1WLsu3HGR4j0x+f/0pnDEkK+iyRKSBFArSKDbvK+buuauZ9eEOumWmcPdlo/jyuD4kaBBZpEVRKMhncqikkodfXcvz72wiMRTiB+cPYdpZA0lP1ktLpCXSO1eOS0VVhN8t3syvX1lLQVklXxnfhx9dOIzu7VODLk1EPgOFghwTd2fexzu5c04em/aVcOaQLG6dOoIRPes9ZUVEWhCFgjTYiq0HmT5rFUs2HWBIt3Y8+42TmTi0qy6DKdKKKBTkqPIPlHD33NXM/GA7We2Smf7FkVye05fEhFDQpYlII1MoSL0Kyip59LX1PPPWRgy48ZzB/NvEQbRL0ctGpLXSu1s+pTIc4YX3tvDggrXsL67gS2N7c/OkYfTqmBZ0aSISZwoFqebuvJK7mzvm5LJhTzGnDuzMzy46gZG9OwRdmog0EYWCAPDRtkNMn5XLOxv2MbBrBk9em8P5I7ppEFmkjVEotHE7DpVyz7zV/G35NjqlJ/PLS07kygnZJGkQWaRNUii0UUXlVTzx+nqefGMDEYdpZw3ke+cMpn1qUtCliUiAFAptTFU4wktL87n/5TXsLSrnC6N78eNJw+jbOT3o0kSkGVAotCELV+/mjtm5rNlVRE6/Tjx57XjGZncKuiwRaUYUCm1A7o4C7pidyxtr99KvSzqPXzOOSSf20CCyiHyKQqEV21VQxv3z1/CnZVvJTE3ivz5/Al87tR/JiRpEFpG6KRRaoZKKKmYs2sATr2+gKhLhG6cP4PvnDqZjenLQpYlIMxfXUDCzycBDQALwlLvfWU+7y4A/ASe7+9J41tSahSPOX97P5775q9lVUM7Uk3pwy+Th9OuSEXRpItJCxC0UzCwBeAS4AMgHlpjZTHdfVatdJnAT8G68amkL3ly7l+mzc8ndUcCYvh155Kpx5PTvHHRZItLCxPObwgRgnbtvADCzF4FLgFW12v0PcDdwcxxrabXW7irkjtm5vLZ6D306pfHwlWP5/KieGkQWkeMSz1DoDWytsZwPnFKzgZmNBfq6+7/MrN5QMLNpwDSA7OzsOJTa8uwpLOeBBWt48b0tZKQkcuvU4Vz7uf6kJiUEXZqItGDxDIW6Pqp69UqzEPAAcN3RHsjdZwAzAHJycvwozVu1ssowT7+5kccWrqesMsy1n+vPTecNoXOGBpFF5LOLZyjkA31rLPcBttdYzgRGAgtjuzp6ADPN7AsabP60SMT5+4pt3DNvNTsOlXHBCd356ZThDOzaLujSRKQViWcoLAGGmNkAYBtwBXDVJyvd/RCQ9cmymS0EblYgfNriDfuYPiuXD7cd4qTeHXjg8jGcOrBL0GWJSCsUt1Bw9yozuxGYR/SQ1Gfc/WMz+yWw1N1nxuu5W4sNe4r41Zw8Xl61i14dUnng8tFcMro3oZAGkUUkPuJ6noK7zwZm17rv5/W0nRjPWlqS/cUV/PqVtfx+8WZSkxL48aRhXH/GAA0ii0jc6YzmZqSsMszzb2/iN6+to7i8iisnZPPDC4aS1S4l6NJEpI1QKDQD7s4/V+7g7rl55B8o5dzh3fjplOEM6Z4ZdGki0sYoFAK2dNN+bp+Vy4qtBxnRsz1/uGEUpw/OOnpHEZE4UCgEZPO+Yu6ck8ecj3bSvX0K91w2ii+N60OCBpFFJEAKhSZ2sKSCh19dx2/f2URSQogfnj+Ub501gPRk/VeISPD0l6iJVFRF+O07m3j41XUUllXy1Zy+/McFQ+nWPjXo0kREqikU4szdmfvRTu6cm8fmfSWcOSSL/7xoBMN7tA+6NBGRT1EoxNHyLQeYPiuXpZsPMKx7Js9/cwJnD+0adFkiIvVSKMTB1v0l3D1vNf/8YDtZ7VL41ZdO4ivj+5CYoMtgikjzplBoRIdKK3n0tXU8+9YmQiG46dzBTDt7EO1StJlFpGXQX6tGUBmO8IfFm3nolbUcLK3ky+P68KMLh9KzQ1rQpYmIHBOFwmfg7ry8ahd3zsljw95iThvUhVunjmBk7w5BlyYiclwUCsdpZf5Bps/K5d2N+xnUNYOnv57DucO76TKYItKiKRSO0faDpdwzbzV/W76NzhnJ/M+lI7ni5L4kaRBZRFoBhUIDFZZV8tjC9Tz95kYc+M7EQXxn4iDapyYFXZqISKNRKBxFVTjCi0u28uCCNewtquDSMb24edIw+nRKD7o0EZFGp1Coh7uzcPUe7pidy9rdRUzo35mnvz6C0X07Bl2aiEjcKBTqsGp7AdNnr+Ktdfvo3yWdx68Zz6QTu2sQWURaPYVCDbsKyrh33mr+/H4+HdKS+MXFJ3D1Kf1ITtQgsoi0DXENBTObDDwEJABPufudtdb/B3ADUAXsAb7p7pvjWVNdisureGLRBp5ctIFwxLn5EYHzAAAMrklEQVThjAHceM4QOqRrEFlE2pa4hYKZJQCPABcA+cASM5vp7qtqNFsO5Lh7iZl9B7gbuDxeNdUWjjh/XraV++avYXdhOReN6sktk4aT3UWDyCLSNsXzm8IEYJ27bwAwsxeBS4DqUHD312q0XwxcE8d6DrNoTXQQOW9nIWOzO/LYNeMZ369TUz29iEizFM9Q6A1srbGcD5xyhPbXA3PiWE+1597ayG3/XEXfzmn85qqxXHRSTw0ii4gQ31Co66+s19nQ7BogBzi7nvXTgGkA2dnZn7mwi0b1ojLsXHtaP1ISEz7z44mItBbxPKwmH+hbY7kPsL12IzM7H/hP4AvuXl7XA7n7DHfPcfecrl0/+0Vqumam8K2zBioQRERqiWcoLAGGmNkAM0sGrgBm1mxgZmOBJ4gGwu441iIiIg0Qt1Bw9yrgRmAekAu85O4fm9kvzewLsWb3AO2AP5nZCjObWc/DiYhIE4jreQruPhuYXeu+n9e4fX48n19ERI6NTtUVEZFqCgUREammUBARkWoKBRERqaZQEBGRagoFERGpplAQEZFqCgUREammUBARkWoKBRERqaZQEBGRagoFERGpplAQEZFqCgUREammUBARkWoKBRERqaZQEBGRagoFERGpplAQEZFqbTIUwh6mPFxKxCMN7uNeiUeKcfcG96mqrKK0qPQ4+pQdY58wpcXlx9RHRKQuifF8cDObDDwEJABPufudtdanAL8FxgP7gMvdfVO86ol4mNUF75NX+D5VXkVGYntGdziD3ukD6u3jHsbLX4PyReAVEMrC0y4mlDSs3j7hqjDv/HMpS+etoKqiik49OnLe1WfR/8S+9fapqqzinX8uY9mCD6mqCtOlZyfOu/J0sof3PkKfMG/P/5AVb66hqipMVo+OnHvpePoM6tawDSIiUkvcvimYWQLwCDAFOAG40sxOqNXseuCAuw8GHgDuilc9AHkFy1h56B1SQxl0TMoiHAnz1t5Z7C3fUW8fL3sZyuaBtYeEXuDlUPwMXrWl3j5v/HUxb/3tPTI7Z9K1bxYVpZX86b6Z7Nq8p94+r/95Me/86306dMmkW58ulBWV8acHZrF76776+/zzfd595WPad86ga6+OFBeV8ucnX2PvzoMN2yAiIrXEc/fRBGCdu29w9wrgReCSWm0uAZ6P3f4zcJ6ZWTyKqYpUsrpwOe0Tu5AYSgIgNSGNpFAyawqX19nHvRwq3oRQD7Dk6J2hTCAZL3+zzj5lJeW8//JKumVnkZSciJmR0SGdxMRE3n95Zd19isv4YOEquvXtQmKsT7uOGSSEjBULP66zT3FhGR8sXkf33p1ITErAzMjskA4GKxevP7aNIyISE89Q6A1srbGcH7uvzjbuXgUcArrUfiAzm2ZmS81s6Z499X/aPpKKSDlVXkVi6PA9ZsmhVAoqD9TdyUuAMFhSrYLSIVJ3HaVFZUQiTkJiwmH3p7VLZd+Oup+nuKAU4FN9UjNS2be97j4lRWUYRijh8P/C1NQk9u86VPfvIyJyFPEMhbo+8dceCW1IG9x9hrvnuHtO165dj6uY1IQ0UkPpVETKDru/NFxMt9R69ttbJlgaeGmtFQWQOLDOLpmdMkhOTaa8tOKw+4sOFdN3eK86+7TvkkliciIVZZWH3V9cUEJ2PX06dM4gITFEZUXVYfeXFJVrTEFEjls8QyEfqDmy2gfYXl8bM0sEOgD741FMyBIY3fE0iqoOUVxVSGWkgoLK/SRYIkPajamzj1kipF4Ekb0QOQBeBpGdQBqWcnqdfRKTEpl4+Wns23GAgn2FlJdWsCd/H6kZKYw996Q6+yQlJ3LWl09h344DFO4vqu6T3j6dUWfVHoaJSk5J4owpo9m74yCFB0soL61g9/YDZLRPY+SEQce1jURE4nn00RJgiJkNALYBVwBX1WozE/g68A5wGfCqx/G4yuyMYaQkpJNX8D5FVYfolzGMYZljyUzqWG+fUPJ43DLx8kXRcEjKwVLOxkKd6+1z0pkjyOyUwXtzlnNobyGjzh7ByZPH0r5LZr19Rp99ApmdMlgyfyWF+4sYffYJ5Fw4msxOGfX2GXvGUNp3SmfZotUUHixh7OlDGX/WcNq1T2vYBhERqcXieWy7mU0FHiR6SOoz7j7dzH4JLHX3mWaWCvwOGEv0G8IV7r7hSI+Zk5PjS5cujVvNIiKtkZktc/eco7WL63kK7j4bmF3rvp/XuF0GfCWeNYiISMO1yTOaRUSkbgoFERGpplAQEZFqCgUREammUBARkWoKBRERqaZQEBGRanE9eS0ezGwPsDnoOuIsC9gbdBEB0zbQNgBtA2i8bdDP3Y86eVyLC4W2wMyWNuTMw9ZM20DbALQNoOm3gXYfiYhINYWCiIhUUyg0TzOCLqAZ0DbQNgBtA2jibaAxBRERqaZvCiIiUk2hEDAzSzWz98zsAzP72Mz+O3b/c2a20cxWxH7qvjxcK2FmCWa23Mz+FVseYGbvmtlaM/ujmSUHXWO81bEN2tprYJOZfRj7XZfG7utsZi/HXgcvm1mnoOuMp3q2wW1mtq3G62BqPGtQKASvHDjX3UcDY4DJZnZqbN2P3X1M7GdFcCU2iX8Hcmss3wU84O5DgAPA9YFU1bRqbwNoW68BgHNiv+snh2D+BHgl9jp4Jbbc2tXeBhB9L3zyOphdb89GoFAImEcVxRaTYj9taqDHzPoAFwFPxZYNOBf4c6zJ88ClwVTXNGpvA6l2CdH/f2gDr4PmQKHQDMR2G6wAdgMvu/u7sVXTzWylmT1gZikBlhhvDwL/D4jElrsAB929KracD/QOorAmVHsbfKKtvAYg+mFovpktM7Npsfu6u/sOgNi/3QKrrmnUtQ0Aboy9Dp6J9y40hUIz4O5hdx8D9AEmmNlI4KfAcOBkoDNwS4Alxo2ZfR7Y7e7Lat5dR9NW++2pnm0AbeQ1UMPp7j4OmAJ8z8zOCrqgANS1DR4DBhHdvbwDuC+eBSgUmhF3PwgsBCa7+47YrqVy4FlgQqDFxc/pwBfMbBPwItHdRg8CHc3sk2uI9wG2B1Nek/jUNjCz37eh1wAA7r499u9u4G9Ef99dZtYTIPbv7uAqjL+6toG774p9cIwATxLn14FCIWBm1tXMOsZupwHnA3k13ghGdD/qR8FVGT/u/lN37+Pu/YErgFfd/WrgNeCyWLOvA/8IqMS4q2cbXNNWXgMAZpZhZpmf3AYuJPr7ziT6/w+t/HVQ3zb45HUQ80Xi/DpIPHoTibOewPNmlkA0pF9y93+Z2atm1pXorpQVwL8FWWQAbgFeNLPbgeXA0wHXE4Q/tKHXQHfgb9H8IxH4X3efa2ZLgJfM7HpgC/CVAGuMt/q2we9ihyM7sAn4djyL0BnNIiJSTbuPRESkmkJBRESqKRRERKSaQkFERKopFEREpJoOSZVWw8y6EJ00DaAHEAb2xJYnuHtFIIUdgZl9E5jt7juDrkUEdEiqtFJmdhtQ5O73NoNaEtw9XM+6N4Ebj2UGVDNLrDEvlEij0u4jaRPM7Oux61asMLNHzSxkZolmdtDM7jGz981snpmdYmavm9mGT+atN7MbzOxvsfWrzexnDXzc283sPaLzWf23mS0xs4/M7HGLupzofDZ/jPVPNrP8Gme4n2pmC2K3bzezJ8zsZeDZ2HPcH3vulWZ2Q9NvVWmNFArS6sUmGPwicFps4sFEotNJAHQA5scmIasAbgPOI3rm7C9rPMyEWJ9xwFVmNqYBj/u+u09w93eAh9z9ZOCk2LrJ7v5HomcqXx6bJ/9ou7fGAhe7+9eAaUQn0ZtAdMK875lZ9vFsH5GaNKYgbcH5RP9wLo1NIZAGbI2tK3X3l2O3PwQOuXuVmX0I9K/xGPPc/QCAmf0dOIPo+6e+x60gOqHZJ84zsx8DqUAWsAyYc4y/xz/cvSx2+0JghJnVDKEhRKeCEDluCgVpCwx4xt3/67A7o7Ow1vx0HiF6JbxPbtd8f9QefPOjPG6pxwbszCwd+A0wzt23xeZzSq2n1ir+7xt87TbFtX6n77r7K4g0Iu0+krZgAfBVM8uC6FFKx7Gr5UIz6xj7A38J8NYxPG4a0ZDZG5sF88s11hUCmTWWNwHjY7drtqttHvDdT6YXN7NhsVl2RT4TfVOQVs/dPzSz/wYWmFkIqCQ64+ixXKPhTeB/iV7s5HefHC3UkMd1931m9jzRKY83A+/WWP0s8JSZlRIdt7gNeNLMdgLvHaGeJ4BsYEVs19VuomEl8pnokFSRo4gd2TPS3X8QdC0i8abdRyIiUk3fFEREpJq+KYiISDWFgoiIVFMoiIhINYWCiIhUUyiIiEg1hYKIiFT7/90JWNfD2fB1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = np.random.rand(len(x_train))\n",
    "plt.plot(np.unique(x_train), np.poly1d(np.polyfit(x_train,y_train,1))(np.unique(x_train)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x_train, y_train,c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression explanation\n",
    "# input -> logit -> softmax (output probability) -> Truelabels\n",
    "# \"logistic function\" g(y)= 1/(1+e**-y) where y is your linear equation b1x+b0\n",
    "# g(y) = Estimated probability that y = 1 given x\n",
    "\n",
    "#Softmax function g()\n",
    "# Multi-class logistic regression\n",
    "# Generalization of logistic function\n",
    "\n",
    "# Cross entropy function\n",
    "# S prediction\n",
    "# L true label\n",
    "# Cross entropy D(S,L) = L*logS - (1-L)*log(1-S)\n",
    "# if L = 0(label)\n",
    "#    D(S,0)= -log(1-S)\n",
    "#        -log(1-S): less positive if S ->0\n",
    "#        -log(1-S): more positive if S ->1 (Bigger Loss)\n",
    "# if L = 1(label)\n",
    "#    D(S,1)= logS\n",
    "#        logS: less negative if S ->1\n",
    "#        logS: more negative if S ->1 (Bigger Loss)\n",
    "\n",
    "# Cross Entropy Loss L\n",
    "# the goal is to minimize the cross entropy loss\n",
    "# L = ( 1/N )* SUM(D(g(Bn*xi+B0),Li))\n",
    "# Where Bn are the coefficients, B0 the bias, N the number of observations, i the index of the observation\n",
    "# This equation is just summing all the distances and taking the average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################\n",
    "#  Import Libraries\n",
    "###################################################################\n",
    "# Logistic regressions are ussed in classification problems\n",
    "# The input might be anything and the output is the probability of belonging or not to a category\n",
    "\n",
    "#in linear regression the output is a numeric value given the input\n",
    "# in logistic regression the output is a probability [0,1] given input belonging to a class\n",
    "\n",
    "# 7 steps\n",
    "# load the data\n",
    "# make the dataset iterable\n",
    "# create the model class\n",
    "# instantiate the model\n",
    "# instantiate the loss class\n",
    "# instantiate the optimizer class\n",
    "# train the model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms # this module will be used to transform the dataset into tensors\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "# Loading the training dataset\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(), #using the torchvision.transforms\n",
    "                            download=True)\n",
    "\n",
    "len(train_dataset)\n",
    "# pytorch works best with iterable data to feed to the model\n",
    "# train_dataset is a dataset object\n",
    "# it has a list of tuples with two tensors\n",
    "# the first tensor is a 1,m,n image \n",
    "# the second tensor is a scalar with the value of the class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2228ba51fd0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset[0][0].size()\n",
    "train_dataset[0][1]\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "a = train_dataset[0][0].numpy().reshape(28,28)\n",
    "plt.imshow(a,cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x222f4c76828>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the test datased\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "len(test_dataset)\n",
    "img = test_dataset[0][0].numpy().reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "\n",
    "aim: make the dataset iterable\n",
    "totaldata: 60000\n",
    "\n",
    "minibatch: 100\n",
    "- a minibatch is the number of examples in 1 iteration.\n",
    "iteration: 3000\n",
    "- 1 iteration: one-minibatch forward & backward pass\n",
    "- forward is running the data through the network to generate the prediction\n",
    "- backward is once calculated the loss, update all the gradients and the weights.\n",
    "\n",
    "epoch\n",
    "- 1 epoch: running through the whole dataset once\n",
    "- epochs = iterations / (totaldata/minimbatch) = 3000 / (60000/100) = 5\n",
    "'''\n",
    "print(len(train_dataset))\n",
    "batch_size = 10\n",
    "n_iters = 9000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Create an iterable object for the training dataset\n",
    "# torch.utils.data.DataLoader \n",
    "# This class creates an iterable object with the dataset and the batch size\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "#Check iterability\n",
    "import collections\n",
    "print(isinstance(train_loader, collections.Iterable))\n",
    "# train_loader is a generator of tensor lists. The first element is a tensor with images of letters\n",
    "# the second one is a one dimension vector with the labels\n",
    "\n",
    "# Create an iterable object for the testing dataset\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 2, 5, 4, 4, 0, 1, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print((i[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "WHY DO WE CREATE AN ITERABLE OBJECT WITH THE DATASET?\n",
    "\n",
    "the main aim is to iterate through the Dataset\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "img_1 = np.ones((28,28))\n",
    "img_2 = np.ones((28,28))\n",
    "lst = [img_1,img_2]\n",
    "# iterate through the data\n",
    "for i in lst:\n",
    "    print (i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        # remember a logistic regression model builds on top of the linear model. \n",
    "        # you just add a softmax function on top of it.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "in this model we have a difference in the input dimension\n",
    "instead of having just one number, like in linear regression\n",
    "we use a 28 x 28 = 784 cells matrix\n",
    "This is the size of the MNIST image\n",
    "\n",
    "and the output cardinality (dimension) is 10\n",
    "0,1,2,3,4,5,6,7,8,9\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "\n",
    "In Logistic regression we use the cross entropy loss. while in linear regresion we use the MSE or L-2\n",
    "'''\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# What happens in nn.CrossEntropyLoss()?\n",
    "# it automatically computes the softmax(logistic/softmax function)\n",
    "# computes cross entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "this is always the same?\n",
    "\n",
    "Simplified equation\n",
    "theta = theta - miu . DeltaTheta\n",
    "- Theta: parameters (our variables)\n",
    "- miu : learning rate(how fast we want to learn)\n",
    "- DeltaTheta: parameters gradient\n",
    "\n",
    "Even simplier equation\n",
    "- paramenters = parameters - learning rate * parameters_gradients\n",
    "- at every iteration, we update our model's parameters\n",
    "'''\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000002228BDF9B48>\n",
      "2\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([ 0.0130,  0.0100,  0.0086,  0.0029, -0.0082, -0.0306, -0.0257, -0.0167,\n",
      "        -0.0175,  0.0199], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nQuick dot product review:\\nif A = size(100,10)\\nB = (10,1)\\nA.B = (100,10) . (10.1) = (100,1)\\n\\nElementwise operations.\\n'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parameters in Depth\n",
    "\n",
    "\"\"\"\n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "#FC 1 parameters (coefficients of x) \n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC1 bias parameters ()\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "print(list(model.parameters())[1])\n",
    "\n",
    "\"\"\"\n",
    "Quick dot product review:\n",
    "if A = size(100,10)\n",
    "B = (10,1)\n",
    "A.B = (100,10) . (10.1) = (100,1)\n",
    "\n",
    "Elementwise operations.\n",
    "\"\"\"\n",
    "# in our model the input has the size of 784 (image) and the output is 10\n",
    "# so A*x+b = (10,784) . (784,1) +(10,1)\n",
    "# A = (10,784)\n",
    "# x = (784,1)\n",
    "# b = (10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.9142248630523682. Accuracy: 65\n",
      "Iteration: 1000. Loss: 1.5418040752410889. Accuracy: 76\n",
      "Iteration: 1500. Loss: 1.1456151008605957. Accuracy: 79\n",
      "Iteration: 2000. Loss: 1.1280670166015625. Accuracy: 80\n",
      "Iteration: 2500. Loss: 1.0603115558624268. Accuracy: 82\n",
      "Iteration: 3000. Loss: 1.0384438037872314. Accuracy: 82\n",
      "Iteration: 3500. Loss: 0.7691559791564941. Accuracy: 83\n",
      "Iteration: 4000. Loss: 0.8503836393356323. Accuracy: 83\n",
      "Iteration: 4500. Loss: 1.1137745380401611. Accuracy: 84\n",
      "Iteration: 5000. Loss: 0.7793793082237244. Accuracy: 84\n",
      "Iteration: 5500. Loss: 0.5440720915794373. Accuracy: 85\n",
      "Iteration: 6000. Loss: 0.293224036693573. Accuracy: 85\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "The full process\n",
    "1. Convert inputs(labels to variables)\n",
    "2. Clear gradient buffers\n",
    "3. Get output given inputs\n",
    "4. Get loss\n",
    "5. Get gradients with respect to parameters\n",
    "6. Update parametes using gradients\n",
    "- parameters = parameters - learning_rate * parameters_gradients\n",
    "7. Repeat\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, 28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        #print(loss)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            #######################\n",
    "            # Calculate Accuracy  # \n",
    "            #######################\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = Variable(images.view(-1, 28*28).cuda())\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                # torch.max(matrix,1) will return as second return the index of the column of the element with larges\n",
    "                # value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if tourch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "            # The accuracy is essentially the proportion of correct predictions over the total predictions\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data.cpu().numpy(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "100 * correct / total\n",
    "print((outputs.data.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 9, 0, 1, 4, 7, 4, 5, 6, 7, 8, 0, 8, 2, 3, 4, 7, 8, 9, 7, 8, 6, 4, 1,\n",
      "        4, 7, 2, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 6, 0, 0, 6, 3, 5, 8, 9, 1, 4,\n",
      "        0, 6, 1, 0, 0, 0, 0, 8, 1, 7, 7, 3, 4, 6, 0, 7, 0, 3, 6, 8, 7, 1, 3, 2,\n",
      "        4, 9, 4, 2, 6, 4, 1, 7, 2, 6, 6, 0, 1, 2, 8, 4, 5, 6, 7, 8, 4, 0, 1, 2,\n",
      "        3, 4, 8, 6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_ ,a = torch.max(outputs.data,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7112, -2.3129, -1.2588, -0.3256,  1.9867,  0.4748, -1.2334,  0.3778,\n",
       "         1.2296,  2.5893], device='cuda:0')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.data[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break down accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([[-3.0472e-01, -2.1223e+00, -6.9842e-01, -5.2112e-02, -1.7934e-01,\n",
      "         -5.6558e-01, -2.0788e+00,  4.7111e+00, -4.3222e-01,  1.4220e+00],\n",
      "        [ 8.4508e-01, -2.8492e-01,  2.9942e+00,  1.6921e+00, -3.1208e+00,\n",
      "          1.3958e+00,  2.1982e+00, -3.2342e+00,  6.3249e-01, -2.6854e+00],\n",
      "        [-1.3408e+00,  3.4861e+00,  3.2176e-01,  1.5240e-01, -1.0850e+00,\n",
      "         -5.2142e-01, -2.8940e-01, -2.8135e-01,  3.3089e-01, -5.4214e-01],\n",
      "        [ 4.7567e+00, -4.1510e+00, -6.5326e-02, -6.4061e-01, -1.8337e+00,\n",
      "          1.3717e+00,  1.7201e+00,  5.3545e-01, -9.2654e-01, -5.3146e-01],\n",
      "        [-3.0444e-01, -3.3412e+00,  4.2712e-01, -1.1843e+00,  2.6361e+00,\n",
      "         -8.5168e-01, -4.0178e-03,  6.1945e-01,  1.2767e-01,  1.0666e+00],\n",
      "        [-2.0410e+00,  4.1713e+00,  2.2299e-01,  3.5474e-01, -1.2505e+00,\n",
      "         -7.1705e-01, -1.2129e+00,  4.2741e-02,  6.3513e-01, -2.6545e-01],\n",
      "        [-2.0104e+00, -2.1280e+00, -1.5263e+00,  3.7151e-01,  2.4226e+00,\n",
      "          6.4379e-01, -1.3104e+00,  8.1602e-01,  1.0849e+00,  1.2724e+00],\n",
      "        [-2.4301e+00, -7.2302e-01, -1.1054e+00, -4.5667e-01,  1.4938e+00,\n",
      "          7.9206e-01,  9.3044e-02, -1.1779e-01,  1.1420e-01,  1.9171e+00],\n",
      "        [ 3.6969e-01, -7.9983e-01,  1.2877e+00, -2.1691e+00,  9.0071e-01,\n",
      "          2.5645e-01,  1.3933e+00, -1.8129e+00,  9.4493e-02,  2.0335e-01],\n",
      "        [-7.5966e-01, -1.9040e+00, -2.0004e+00, -1.9020e+00,  1.8425e+00,\n",
      "         -1.4543e-01, -1.0371e+00,  2.7299e+00, -2.1757e-02,  3.1761e+00],\n",
      "        [ 4.8216e+00, -3.0243e+00,  9.1133e-01,  1.3870e+00, -1.5917e+00,\n",
      "          2.0648e+00, -9.9709e-01, -2.1489e+00,  1.1613e+00, -3.2554e+00],\n",
      "        [ 8.3347e-01, -8.5513e-01,  6.9684e-01, -1.5106e-01,  3.5248e-01,\n",
      "         -6.4825e-01,  1.0799e+00, -1.8410e+00,  6.4834e-01, -1.2482e+00],\n",
      "        [-1.1293e+00, -2.8155e+00, -1.4331e+00, -1.7415e+00,  2.3248e+00,\n",
      "         -1.1457e-01, -6.7307e-01,  1.4801e+00,  3.7699e-01,  3.5383e+00],\n",
      "        [ 4.7419e+00, -4.1556e+00, -3.2514e-01, -1.0508e+00, -7.6747e-01,\n",
      "          1.3340e+00, -6.1529e-01, -9.0010e-01,  1.2570e+00,  5.6372e-01],\n",
      "        [-2.1999e+00,  4.1741e+00, -3.4036e-02,  9.6505e-01, -1.9338e+00,\n",
      "         -2.3461e-01, -1.5413e-01, -3.8762e-01,  3.4461e-01, -3.5483e-01],\n",
      "        [ 5.7062e-01, -1.4098e+00, -6.9458e-02,  1.5788e+00, -8.5362e-01,\n",
      "          1.8359e+00, -8.7642e-01, -7.5470e-01,  7.5871e-01, -1.5985e+00],\n",
      "        [-6.6617e-01, -3.5512e+00, -7.4139e-03, -1.0157e+00,  1.8658e+00,\n",
      "         -1.1339e+00, -6.0810e-01,  1.3096e+00,  3.3563e-01,  2.8341e+00],\n",
      "        [ 5.5436e-01, -2.5153e+00, -9.7237e-01,  1.0110e+00, -7.7045e-01,\n",
      "         -4.0841e-01, -1.3967e+00,  4.6129e+00, -8.3833e-01,  7.1654e-01],\n",
      "        [-1.3010e+00, -6.2051e-01,  1.3455e-01,  2.0701e+00, -1.0038e+00,\n",
      "          8.3113e-01,  1.2493e+00, -1.0403e+00,  2.9355e-01, -6.9945e-01],\n",
      "        [-1.5537e+00, -2.4805e+00, -8.3050e-01, -4.8756e-01,  3.4174e+00,\n",
      "         -1.2283e-02, -3.9218e-01, -4.1326e-03, -2.4586e-01,  2.0120e+00],\n",
      "        [-1.3070e+00, -1.2155e+00, -2.5435e+00,  1.7379e-01,  8.2478e-01,\n",
      "          6.2569e-01, -2.5548e+00,  2.5340e+00,  3.6644e-01,  2.7987e+00],\n",
      "        [-9.3805e-01, -2.6209e+00,  8.7309e-02,  1.5088e-01,  6.9427e-01,\n",
      "          1.2126e+00,  3.4086e+00, -2.5566e+00,  4.8936e-01, -1.1661e-01],\n",
      "        [-7.8310e-01,  1.8741e-01,  5.7247e-01, -1.0098e+00,  1.4220e+00,\n",
      "         -2.0406e+00,  2.0337e+00, -1.5001e-01, -3.5760e-01, -2.9731e-01],\n",
      "        [ 1.0690e-01, -1.9772e+00, -8.6414e-01,  6.2712e-01, -3.6012e-02,\n",
      "          2.6453e+00,  4.3563e-01, -1.7789e+00,  1.2187e+00, -1.0424e-02],\n",
      "        [-1.1904e+00, -1.8122e+00, -7.9044e-02, -1.6405e-01,  2.2699e+00,\n",
      "         -5.2934e-01, -4.1351e-01,  5.6299e-01, -3.8958e-01,  1.4234e+00],\n",
      "        [ 6.6588e+00, -4.7753e+00,  9.6152e-01, -2.1312e+00, -4.6490e-01,\n",
      "          2.3281e+00,  1.6848e+00, -1.3590e+00,  2.9600e-02, -2.3954e+00],\n",
      "        [-4.0685e-01, -2.0283e+00, -6.7290e-01,  1.1073e-01,  9.5084e-02,\n",
      "         -1.9631e-01, -1.0383e+00,  2.9547e+00, -8.0691e-01,  1.8604e+00],\n",
      "        [-7.5650e-01, -3.7401e+00, -7.5323e-01, -1.3325e+00,  4.0258e+00,\n",
      "          1.7414e-01,  6.5293e-02, -2.4416e-01,  1.4308e-01,  2.4091e+00],\n",
      "        [ 4.5354e+00, -4.0389e+00,  5.3361e-01,  1.3081e+00, -2.2449e+00,\n",
      "          1.5252e+00, -6.0777e-01, -1.0064e+00,  1.3276e+00, -8.3867e-01],\n",
      "        [-1.8664e+00,  2.4349e+00, -5.6468e-01,  3.1086e-01, -7.1592e-01,\n",
      "          4.9941e-01,  3.0656e-01, -3.1672e-01,  7.2052e-01, -5.2974e-01],\n",
      "        [-1.3983e+00, -5.7551e-01, -1.3791e+00,  3.9690e+00, -2.1526e+00,\n",
      "          1.6528e+00, -1.0150e+00,  8.1503e-01,  1.7371e-01, -1.3367e-01],\n",
      "        [-1.8179e+00,  1.8869e+00, -5.0038e-01,  6.2559e-01, -5.6567e-01,\n",
      "          2.3708e-01, -2.7470e-01,  1.5609e-01,  2.0413e-01,  2.2610e-01],\n",
      "        [-1.7207e+00, -1.4209e+00, -9.5926e-01,  3.7404e+00, -6.1529e-01,\n",
      "          2.4615e+00, -9.3598e-01, -1.7718e+00,  8.9289e-01, -3.9122e-01],\n",
      "        [ 2.5253e+00, -2.8557e+00,  1.0574e+00, -3.1716e+00,  1.2502e+00,\n",
      "          5.6026e-01,  2.2786e+00, -1.5530e+00, -1.8889e-02, -8.7303e-01],\n",
      "        [-1.4453e+00, -8.5795e-01,  1.0964e+00, -1.7405e-01, -2.0309e-01,\n",
      "         -6.6812e-01, -2.5390e+00,  3.1183e+00,  7.2327e-01,  1.0756e+00],\n",
      "        [ 5.3723e-01, -1.8052e+00,  4.4227e+00,  5.2474e-01, -1.2397e+00,\n",
      "          7.0235e-01,  6.0597e-01, -5.4279e-01,  3.9935e-01, -3.0235e+00],\n",
      "        [-8.5664e-01, -2.6901e+00,  3.0572e-01,  2.0498e-01, -3.6588e-01,\n",
      "         -5.1151e-01, -8.9320e-01,  3.8177e+00, -2.6954e-01,  1.7024e+00],\n",
      "        [-2.3415e+00,  3.4255e+00, -6.8505e-01,  2.5804e-01, -1.0918e+00,\n",
      "          1.3384e-01, -8.3498e-02,  4.7742e-02,  6.0899e-01, -1.1638e-01],\n",
      "        [ 6.9805e-01,  5.0705e-01,  1.6897e+00,  1.9660e+00, -3.2696e+00,\n",
      "          7.6433e-01,  7.2991e-01, -2.0069e+00,  1.1061e+00, -2.2399e+00],\n",
      "        [-2.1117e+00,  4.4145e+00, -3.5288e-01,  7.4000e-01, -2.3408e+00,\n",
      "         -5.2470e-03, -1.9049e-01, -9.2151e-01,  1.1730e+00, -3.9273e-01],\n",
      "        [-1.1657e+00,  2.5980e+00, -2.4617e-02,  1.2775e-01, -9.6796e-01,\n",
      "         -1.9710e-01, -9.3846e-02, -2.3194e-01,  9.6418e-02, -2.8568e-01],\n",
      "        [-1.3953e+00, -1.6400e+00, -1.2926e-01, -4.4557e-01, -2.2324e-01,\n",
      "         -4.1914e-01, -1.0815e+00,  3.3259e+00, -4.9324e-01,  2.0395e+00],\n",
      "        [-3.4133e+00, -8.3829e-01, -6.2936e-01, -6.2934e-01,  3.6952e+00,\n",
      "         -1.1941e+00, -1.4633e+00,  8.3416e-01,  5.8113e-01,  2.2948e+00],\n",
      "        [-7.2289e-01,  1.2093e+00,  2.1177e+00, -1.3694e-01, -4.4936e-01,\n",
      "         -6.5094e-01,  3.7402e-01, -1.8666e+00,  8.8237e-01, -9.4177e-01],\n",
      "        [-1.7177e+00,  1.0617e-01, -4.9796e-02,  2.2011e+00, -1.1073e+00,\n",
      "          8.3973e-01,  5.1654e-01, -4.1064e-01, -4.6998e-02, -8.1015e-01],\n",
      "        [ 3.7989e-01, -2.2021e+00, -9.9341e-01,  2.4677e+00, -6.7071e-01,\n",
      "          2.4971e+00, -2.5044e-01, -2.1637e+00,  1.5253e+00, -4.6269e-01],\n",
      "        [-2.8920e+00,  6.0614e-01,  2.4955e-02,  1.4321e+00, -1.8940e-01,\n",
      "          6.9829e-01,  1.0775e-02, -1.2449e-01,  4.3039e-01,  1.9474e-01],\n",
      "        [-1.1582e+00, -7.8559e-01,  2.6135e+00, -6.0929e-01,  8.4512e-01,\n",
      "         -9.1262e-01,  1.0882e+00, -6.4520e-01, -1.5907e-01,  1.4530e-01],\n",
      "        [-2.0691e+00, -4.5640e+00, -2.6875e+00, -1.8144e-01,  4.5792e+00,\n",
      "          7.1669e-01, -1.3872e+00,  2.8150e-01,  1.1815e+00,  3.2377e+00],\n",
      "        [-7.5019e-01, -3.3074e+00,  6.8312e-01, -1.1624e+00,  3.8343e+00,\n",
      "         -1.8259e+00,  2.7732e-01,  3.9608e-01, -3.6789e-01,  1.4913e+00],\n",
      "        [ 3.8486e-01, -1.9815e+00,  3.6616e-01,  5.0475e-01, -7.5061e-01,\n",
      "          9.0034e-01,  3.6820e+00, -1.8399e+00, -7.0283e-02, -7.8929e-01],\n",
      "        [-2.7778e-01, -1.7516e+00, -4.2231e-01,  3.0907e+00, -1.1166e+00,\n",
      "          1.3372e+00, -6.8667e-02, -7.9772e-01, -3.9425e-01,  1.7208e-01],\n",
      "        [ 7.6672e-01, -2.1923e+00, -2.2307e+00, -1.7895e-01,  1.2083e+00,\n",
      "          2.5885e+00, -3.7867e-01, -6.0664e-01, -9.3596e-02,  6.1348e-01],\n",
      "        [ 4.6532e-01, -1.4057e+00, -7.8229e-01,  1.2271e+00,  7.9798e-02,\n",
      "          1.2601e+00, -3.9009e-01, -1.0270e+00,  8.9349e-01, -5.4696e-01],\n",
      "        [-1.7799e-01, -7.4796e-01,  2.1101e+00, -3.3489e-02,  6.4023e-01,\n",
      "         -1.5509e+00,  1.6111e+00, -1.0207e+00,  2.6888e-01, -6.8391e-01],\n",
      "        [ 2.6784e+00, -4.0132e+00, -8.8684e-01,  3.3239e-01, -1.1751e+00,\n",
      "          1.9547e+00,  3.7236e-01, -1.5106e+00,  2.3860e+00, -1.4944e-01],\n",
      "        [-4.3800e-01, -4.3215e+00, -2.3501e-01, -1.0338e+00,  4.4661e+00,\n",
      "         -1.3185e-01,  4.2750e-01, -5.7921e-01,  4.8443e-02,  1.2167e+00],\n",
      "        [-1.3211e+00,  3.5456e+00,  1.5749e-01,  4.5576e-01, -1.5566e+00,\n",
      "         -4.5292e-01, -8.6693e-01, -2.0227e-01,  4.6949e-01, -7.8822e-02],\n",
      "        [-3.0259e-01, -3.1407e+00, -1.6937e+00, -1.5251e+00,  2.6230e+00,\n",
      "         -6.4698e-01, -1.9139e-01,  1.7480e+00, -4.7364e-01,  3.5912e+00],\n",
      "        [ 2.5091e-01,  2.4254e-01, -8.0481e-01, -8.1776e-01,  5.5792e-01,\n",
      "          1.0358e+00, -7.1644e-01,  5.6023e-01,  1.6202e-01, -3.9704e-01],\n",
      "        [-7.0486e-01, -2.5387e+00, -1.2197e+00,  1.2034e+00, -9.9059e-02,\n",
      "         -6.9413e-02, -7.1429e-01,  3.6361e+00, -9.5188e-01,  6.9245e-01],\n",
      "        [ 1.9251e-01, -1.7449e+00,  1.8995e+00, -2.5164e+00, -2.2596e-01,\n",
      "          4.4234e-01,  8.9441e-01, -1.3728e+00,  2.2486e+00,  6.4124e-01],\n",
      "        [-1.4565e+00, -1.6813e+00,  1.2823e-01, -6.7062e-01,  1.1365e+00,\n",
      "          3.9739e-01, -1.8863e-01, -2.5640e-01,  6.7999e-01,  1.6490e+00],\n",
      "        [-1.1693e+00, -4.2025e-01,  2.1413e+00,  1.2873e+00, -2.1998e-01,\n",
      "         -1.3951e-01, -7.1337e-01, -1.1504e+00,  5.7275e-01,  4.4925e-01],\n",
      "        [-1.4195e+00, -1.6447e+00,  4.6585e-01, -5.2492e-01,  1.3749e+00,\n",
      "         -8.0124e-01, -1.0360e+00,  2.6888e+00,  4.4449e-02,  1.1390e+00],\n",
      "        [-1.7571e+00, -1.3142e+00, -9.2958e-01,  7.7250e-01,  1.1712e+00,\n",
      "          7.2316e-01, -8.4449e-02, -6.4398e-01,  8.6546e-01,  1.3903e+00],\n",
      "        [ 6.5555e-01, -3.1300e-01,  1.2116e+00, -7.8298e-02,  5.6162e-01,\n",
      "         -1.1528e+00,  1.0774e+00,  4.7127e-01, -6.6586e-01, -1.1871e+00],\n",
      "        [-9.9506e-01, -2.2234e+00,  5.6570e-01, -1.6105e+00,  3.5780e+00,\n",
      "         -1.6381e+00, -3.9110e-01,  4.2095e-01,  2.7893e-01,  1.3015e+00],\n",
      "        [-2.0102e+00, -1.2297e+00, -5.5680e-01,  4.3218e+00, -7.5041e-01,\n",
      "          1.6566e+00, -1.8133e+00, -1.4748e+00,  1.6096e+00, -2.3607e-01],\n",
      "        [ 4.0629e+00, -2.2148e+00,  9.4179e-01, -7.8136e-01, -2.5549e+00,\n",
      "          1.5687e+00,  6.9717e-01, -6.4646e-02, -1.2717e-01, -4.3646e-01],\n",
      "        [ 8.3143e-01, -2.1239e+00, -1.2846e+00,  5.2410e-01, -5.7995e-01,\n",
      "         -5.7906e-01, -1.5320e+00,  4.6268e+00, -7.1582e-01,  6.1558e-01],\n",
      "        [ 6.6777e+00, -4.5540e+00,  1.5754e+00,  1.9545e-01, -1.8921e+00,\n",
      "          2.3779e+00,  1.0305e-01, -2.3393e+00,  1.0471e+00, -2.5179e+00],\n",
      "        [ 2.3384e+00, -1.7810e+00,  3.2440e+00,  2.3017e+00, -1.9441e+00,\n",
      "          2.5647e-01,  6.2239e-01, -1.3585e+00,  3.5941e-01, -3.6541e+00],\n",
      "        [-2.0476e+00,  7.3677e-01,  3.9809e-02, -3.2679e-02, -1.4329e+00,\n",
      "         -4.8038e-01, -1.8026e+00,  1.4669e+00,  1.7867e+00,  1.3482e+00],\n",
      "        [-2.2898e+00,  3.5957e+00, -6.2544e-01,  1.3405e-01, -1.5653e+00,\n",
      "          2.4022e-01, -1.5847e-01, -2.1634e-01,  9.1808e-01, -2.2709e-01],\n",
      "        [-2.8402e+00,  7.1885e-01, -7.5963e-01, -9.1627e-01,  1.3655e+00,\n",
      "         -8.5451e-01, -1.3636e+00,  2.8805e+00,  1.1595e-01,  9.3616e-01],\n",
      "        [-2.8494e-01,  8.2327e-03, -4.9901e-01,  3.6160e+00, -1.7122e+00,\n",
      "          1.9270e+00, -1.0633e+00, -1.6907e+00,  1.0740e+00, -1.3624e+00],\n",
      "        [-1.6331e+00, -7.6659e-01,  1.3090e+00, -8.9030e-01, -3.0840e-01,\n",
      "         -6.8039e-01, -3.6490e-02,  2.6752e+00, -7.0358e-01,  9.7890e-01],\n",
      "        [-2.4504e+00,  1.1328e+00, -1.6036e+00,  1.3535e-01, -2.6133e-01,\n",
      "          1.4306e-01, -1.1714e+00,  4.3133e-01,  1.3599e+00,  1.4353e+00],\n",
      "        [-7.1979e-01, -1.4753e+00, -1.1453e+00, -1.5940e+00, -3.5701e-01,\n",
      "         -2.5625e-01, -2.5255e+00,  5.7902e+00,  2.7716e-01,  1.4540e+00],\n",
      "        [-8.2198e-01, -2.9766e+00, -1.8478e+00, -3.0006e-01,  1.3876e+00,\n",
      "          9.7183e-01, -7.3708e-01,  2.4851e+00, -1.0510e+00,  2.8372e+00],\n",
      "        [ 3.8336e-02, -3.1800e+00,  1.1736e+00, -1.1293e+00,  3.7961e-01,\n",
      "          6.2146e-01,  3.8353e+00, -8.4926e-01, -4.6204e-01,  6.3732e-02],\n",
      "        [-9.7703e-01, -2.1590e+00,  6.5714e+00, -2.6380e-01, -2.3395e-01,\n",
      "         -1.7395e+00,  1.2988e+00, -1.3686e+00,  8.7201e-01, -2.3386e+00],\n",
      "        [-8.8722e-01, -2.8823e+00, -1.1261e+00, -7.6017e-02,  8.9043e-01,\n",
      "         -1.5428e-01, -1.4886e+00,  3.6633e+00, -6.8793e-01,  2.5432e+00],\n",
      "        [-1.4164e+00, -2.9592e-01, -8.8195e-01, -1.0653e+00,  9.5090e-01,\n",
      "          1.3388e+00, -9.6320e-01, -1.1985e+00,  2.0743e+00,  6.4320e-01],\n",
      "        [-1.8409e+00, -4.0001e+00, -1.9124e+00,  9.6445e-02,  5.0849e+00,\n",
      "          1.8802e-01, -5.3662e-01, -9.4872e-01,  7.2742e-01,  2.1289e+00],\n",
      "        [-2.7902e+00,  4.3542e-01, -5.6146e-01, -9.5558e-01, -3.2373e-01,\n",
      "         -1.2103e+00, -2.2510e+00,  5.0055e+00,  4.6542e-01,  1.5896e+00],\n",
      "        [-3.1520e-01, -2.3678e+00, -1.8840e+00,  2.6417e+00, -6.0874e-01,\n",
      "          2.1176e+00,  7.1288e-01, -8.3408e-01, -2.6972e-01, -4.2484e-01],\n",
      "        [-7.0699e-01, -3.4815e+00,  1.2196e+00, -2.1478e+00,  1.9946e+00,\n",
      "         -7.7835e-01,  4.0544e+00, -4.3591e-01, -8.0718e-01,  3.3326e-01],\n",
      "        [-2.5637e+00,  4.5169e+00,  7.0582e-01,  1.5473e-01, -1.0235e+00,\n",
      "         -7.0975e-01, -4.6275e-01, -4.9433e-01,  7.7133e-01, -9.0397e-01],\n",
      "        [ 3.4944e-01, -1.2340e+00, -3.0708e-01,  4.5515e+00, -2.1448e+00,\n",
      "          1.6518e+00, -2.6493e+00, -6.1602e-01,  1.2857e+00, -1.0245e+00],\n",
      "        [-1.4801e+00, -1.0588e+00,  6.1796e-01, -1.4368e+00,  7.5414e-01,\n",
      "         -9.6180e-02,  4.2347e+00, -2.1103e+00,  1.8464e-01,  9.8774e-02],\n",
      "        [-1.4570e+00, -1.8324e-01,  1.3976e-01, -7.9524e-01,  9.3115e-01,\n",
      "          1.0448e-02, -4.5524e-01, -3.2122e-01,  1.0905e+00,  9.3798e-01],\n",
      "        [-1.2950e+00, -1.3044e+00, -1.1311e+00,  4.3691e+00, -2.6244e+00,\n",
      "          2.2956e+00, -2.2556e+00,  1.0499e+00,  8.1884e-01, -8.2598e-02],\n",
      "        [-3.6339e+00,  2.8312e+00, -1.1388e-01,  3.7945e-01, -7.4967e-01,\n",
      "          2.1865e-01,  4.8035e-01, -6.5228e-01,  1.3993e+00, -1.1313e-01],\n",
      "        [-1.5994e+00, -7.1579e-01, -8.7156e-01, -2.2747e+00,  3.8479e+00,\n",
      "         -1.0543e+00,  5.5651e-01, -4.8894e-02, -2.2847e-01,  1.9822e+00],\n",
      "        [-2.0866e+00,  9.7972e-01, -7.2543e-01,  6.0172e-01, -1.9133e-01,\n",
      "          5.6418e-01, -2.9616e-01,  2.2092e-01,  6.1790e-01,  4.1104e-01],\n",
      "        [-3.0679e+00,  1.8796e+00, -1.1093e+00,  4.3134e-01, -4.5646e-01,\n",
      "         -1.7638e-01, -3.4837e-01,  1.3844e+00,  2.8209e-01,  8.1996e-01],\n",
      "        [ 1.4269e+00, -2.0822e+00,  1.2984e+00, -1.7761e+00, -3.2527e-01,\n",
      "          1.4015e+00,  3.3582e+00, -1.7876e+00,  1.6707e-01, -1.3334e+00],\n",
      "        [-2.1499e+00, -2.8527e+00,  1.1374e-01, -9.2324e-01,  2.1990e+00,\n",
      "         -1.7958e+00, -7.5010e-01,  1.4457e+00,  1.5701e-01,  3.9299e+00]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28).cuda())\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28).cuda())\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs.size()) # the batch feeds 100 images at a time to the model\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "tensor([-0.3047, -2.1223, -0.6984, -0.0521, -0.1793, -0.5656, -2.0788,  4.7111,\n",
      "        -0.4322,  1.4220], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28).cuda())\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs[0,:]) #in one particular image\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "tensor(7, device='cuda:0')\n",
      "LABEL FOR IMAGE 0\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28).cuda())\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])\n",
    "        print('LABEL FOR IMAGE 0')\n",
    "        print(labels[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "        4, 0, 7, 4, 0, 1, 3, 1, 3, 0, 7, 2, 7, 1, 3, 1, 1, 7, 4, 2, 3, 5, 3, 2,\n",
       "        4, 4, 6, 3, 5, 5, 2, 0, 4, 1, 9, 5, 7, 8, 9, 2, 7, 9, 2, 4, 3, 0, 7, 0,\n",
       "        2, 8, 1, 7, 3, 7, 9, 7, 9, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 8, 3, 1, 4,\n",
       "        1, 1, 6, 9], device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#    SAVE THE MODEL\n",
    "#############################\n",
    "\n",
    "save_model = True\n",
    "if save_model == True:\n",
    "    torch.save(model.state_dict(),'my_awesomeLogisticmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
