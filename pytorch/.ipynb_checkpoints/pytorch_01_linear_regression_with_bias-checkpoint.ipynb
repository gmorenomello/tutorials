{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Define Data\n",
    "x_train = np.asarray([[1],[2],[1],[1],[4],[3]],dtype = np.uint8)\n",
    "y_correct =  np.asarray([[3],[6],[6],[4],[12],[9]],dtype = np.uint8)\n",
    "\n",
    "# Define Data 2\n",
    "domain_size = 18\n",
    "x_train = np.arange(domain_size,dtype=np.float64)\n",
    "x_train = np.reshape(x_train, (domain_size,1))\n",
    "error = (np.random.rand(x_train.shape[0],x_train.shape[1])-0.5) *10\n",
    "y_correct = x_train * 5  + error\n",
    "\n",
    "\n",
    "class MyLinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__() \n",
    "        # Calling Super Class's constructor\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        # nn.linear is defined in nn.Module\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Here the forward pass is simply a linear function\n",
    "\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "###################################################################\n",
    "\n",
    "model = MyLinearRegressionModel(input_dim,output_dim)\n",
    "\n",
    "criterion = nn.MSELoss()# Mean Squared Loss\n",
    "l_rate = 0.01\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr = l_rate) #Stochastic Gradient Descent\n",
    "\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    epoch +=1\n",
    "    #increase the number of epochs by 1 every time\n",
    "\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_correct))\n",
    "\n",
    "    #clear grads as discussed in prev post\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    #forward to get predicted values\n",
    "\n",
    "    outputs = model.forward(inputs.float())\n",
    "    loss = criterion(outputs, labels.float())\n",
    "    loss.backward()# back props\n",
    "    optimiser.step()# update the parameters\n",
    "    print('epoch {}, loss {}'.format(epoch,loss.data))\n",
    "    \n",
    "\n",
    "    \n",
    "predicted = model.forward(Variable(torch.from_numpy(x_train)).float()).data.numpy()\n",
    "\n",
    "plt.plot(x_train, y_correct, 'go', label = 'from data', alpha = .5)\n",
    "plt.plot(x_train, predicted, label = 'prediction', alpha = 0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
