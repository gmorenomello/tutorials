{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feedforward Neural Networks\n",
    "## 1. About Feedfoward neural network\n",
    "- the difference from the logistic regression is that you add a hidden layer\n",
    "- the hidden layer is a combination of a linear function with a non linear function\n",
    "- the logistic regression (logit -> softmax ) becomes the readout layer\n",
    "\n",
    "## 2. the nonlinear function is also called the activation function\n",
    "- function: takes a number and perfomrs a mathematical operanton\n",
    "- common types of non-linear activation functions:\n",
    "  - ReLUs(Rectified Linear Units)\n",
    "  - Sigmoid\n",
    "  - Tanh\n",
    "  - Threshold\n",
    "  - leaky ReLUs\n",
    "  \n",
    "### Sigmoid(logistic)\n",
    "- $ \\sigma(x) = 1/(1+e^y)$\n",
    "- input number -> [0,1]\n",
    "    - large negative numbers = 0  and large positive numbers  = 1\n",
    "- con\n",
    "1. Activation saturates at 0 or 1 with gradients close to 0\n",
    "  - no signal to update wights - cannot learn\n",
    "  - solution: have to carefully initialize wieghts to prevent this\n",
    "2. Outputs not centered around 0\n",
    "    - if output always positive - gradients always positive or negative - bad for gradient updates\n",
    "\n",
    "### Tanh\n",
    "- $tanh(x) = 2\\sigma(2x)-1$\n",
    "     - a scaled sigmoid function\n",
    "- input number - [-1,1]\n",
    "- Cons:\n",
    "    1. activation saturates at 0  or 1 with gradients close to 0\n",
    "    - no signal to update weights\n",
    "    - solution: carefully initialize weights to prevent this\n",
    "\n",
    "### ReLUs\n",
    "- $f(x) = max(0,x)$\n",
    "- Pros\n",
    "    1. Accelerates convergence - train faster\n",
    "    2. Les computationally expensive operation compared to sigmoid / tanh exponentials\n",
    "- Cons\n",
    "    1. Many ReLU units \"die! - gradients = 0\n",
    "        - solution: careful learn rate choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first feed forward network will be one with a hidden layer and a sigmoidal activation function\n",
    "\n",
    "### Steps\n",
    "1. Load Dataset\n",
    "2. Make Dataset Iterable\n",
    "3. Create the model\n",
    "4. Instantiate the model class\n",
    "5. Instantiate the loss class\n",
    "6. Instantiate the optimizer\n",
    "7. Train Model\n",
    "8. Measure Accuracy\n",
    "9. save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D6264F23B8>\n",
      "4\n",
      "Parameter containing:\n",
      "tensor([-0.0272, -0.0260, -0.0171,  0.0030, -0.0104,  0.0176,  0.0075,  0.0195,\n",
      "        -0.0239,  0.0223,  0.0211, -0.0225,  0.0120,  0.0124,  0.0096,  0.0064,\n",
      "         0.0085, -0.0241,  0.0262,  0.0325, -0.0018,  0.0346, -0.0060, -0.0203,\n",
      "         0.0011, -0.0080,  0.0189,  0.0021,  0.0333,  0.0272, -0.0092,  0.0031,\n",
      "         0.0173,  0.0226, -0.0004, -0.0349,  0.0242,  0.0003,  0.0161,  0.0117,\n",
      "         0.0316,  0.0220,  0.0123, -0.0017, -0.0021,  0.0011,  0.0121,  0.0035,\n",
      "        -0.0219,  0.0307,  0.0159,  0.0261, -0.0211,  0.0229, -0.0066, -0.0020,\n",
      "         0.0250,  0.0106, -0.0117,  0.0224,  0.0251, -0.0091,  0.0061,  0.0337,\n",
      "        -0.0038,  0.0253, -0.0167, -0.0059, -0.0148, -0.0237, -0.0341, -0.0270,\n",
      "         0.0351,  0.0071,  0.0097, -0.0214,  0.0345, -0.0224,  0.0161, -0.0095,\n",
      "        -0.0149, -0.0053, -0.0311,  0.0121, -0.0077,  0.0055, -0.0033, -0.0244,\n",
      "         0.0101,  0.0176, -0.0075,  0.0280,  0.0060,  0.0314, -0.0235,  0.0333,\n",
      "         0.0294, -0.0273,  0.0301,  0.0217], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 13000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        \n",
    "        # Non-linearity \n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "print(list(model.parameters())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.5882385969161987. Accuracy: 86\n",
      "Iteration: 1000. Loss: 0.5010350942611694. Accuracy: 89\n",
      "Iteration: 1500. Loss: 0.24042809009552002. Accuracy: 90\n",
      "Iteration: 2000. Loss: 0.22205448150634766. Accuracy: 91\n",
      "Iteration: 2500. Loss: 0.4286780059337616. Accuracy: 91\n",
      "Iteration: 3000. Loss: 0.4364495575428009. Accuracy: 92\n",
      "Iteration: 3500. Loss: 0.22739818692207336. Accuracy: 92\n",
      "Iteration: 4000. Loss: 0.34756019711494446. Accuracy: 92\n",
      "Iteration: 4500. Loss: 0.24960219860076904. Accuracy: 92\n",
      "Iteration: 5000. Loss: 0.28244122862815857. Accuracy: 93\n",
      "Iteration: 5500. Loss: 0.1531527191400528. Accuracy: 93\n",
      "Iteration: 6000. Loss: 0.30804160237312317. Accuracy: 93\n",
      "Iteration: 6500. Loss: 0.493997722864151. Accuracy: 93\n",
      "Iteration: 7000. Loss: 0.24398483335971832. Accuracy: 93\n",
      "Iteration: 7500. Loss: 0.37047064304351807. Accuracy: 93\n",
      "Iteration: 8000. Loss: 0.3526969254016876. Accuracy: 94\n",
      "Iteration: 8500. Loss: 0.17212581634521484. Accuracy: 94\n",
      "Iteration: 9000. Loss: 0.16020339727401733. Accuracy: 94\n",
      "Iteration: 9500. Loss: 0.09926684200763702. Accuracy: 94\n",
      "Iteration: 10000. Loss: 0.21963900327682495. Accuracy: 94\n",
      "Iteration: 10500. Loss: 0.16288527846336365. Accuracy: 94\n",
      "Iteration: 11000. Loss: 0.15610037744045258. Accuracy: 94\n",
      "Iteration: 11500. Loss: 0.17756490409374237. Accuracy: 95\n",
      "Iteration: 12000. Loss: 0.07930366694927216. Accuracy: 95\n",
      "Iteration: 12500. Loss: 0.1609288454055786. Accuracy: 95\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, 28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = Variable(images.view(-1, 28*28).cuda())\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Feedfoward model with TanH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D62B049468>\n",
      "4\n",
      "Parameter containing:\n",
      "tensor([-0.0201, -0.0026,  0.0316, -0.0200, -0.0347,  0.0013,  0.0238,  0.0269,\n",
      "        -0.0096, -0.0063, -0.0013,  0.0303, -0.0081, -0.0046,  0.0301,  0.0344,\n",
      "        -0.0086, -0.0290,  0.0200, -0.0278,  0.0223,  0.0256, -0.0138, -0.0237,\n",
      "         0.0085, -0.0213,  0.0353, -0.0163,  0.0173, -0.0064,  0.0210,  0.0135,\n",
      "        -0.0329, -0.0134,  0.0117, -0.0293, -0.0229, -0.0259,  0.0228, -0.0139,\n",
      "         0.0207,  0.0137,  0.0067,  0.0153,  0.0294,  0.0201,  0.0125,  0.0258,\n",
      "        -0.0331,  0.0062, -0.0218,  0.0357,  0.0213, -0.0260,  0.0081, -0.0191,\n",
      "         0.0005, -0.0095,  0.0109,  0.0039, -0.0132,  0.0325, -0.0275, -0.0076,\n",
      "         0.0042, -0.0283,  0.0125, -0.0320, -0.0198, -0.0332,  0.0117, -0.0112,\n",
      "        -0.0306,  0.0008, -0.0051,  0.0041,  0.0326, -0.0333, -0.0091, -0.0134,\n",
      "         0.0184, -0.0062, -0.0135, -0.0127,  0.0149, -0.0063,  0.0077,  0.0215,\n",
      "         0.0233, -0.0328,  0.0141,  0.0284, -0.0088, -0.0001,  0.0351,  0.0089,\n",
      "        -0.0082, -0.0295, -0.0030, -0.0278], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 13000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        \n",
    "        # Non-linearity \n",
    "        out = self.tanh(out)\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "print(list(model.parameters())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.3465653657913208. Accuracy: 91\n",
      "Iteration: 1000. Loss: 0.2720365524291992. Accuracy: 92\n",
      "Iteration: 1500. Loss: 0.2544703781604767. Accuracy: 93\n",
      "Iteration: 2000. Loss: 0.2720886170864105. Accuracy: 93\n",
      "Iteration: 2500. Loss: 0.20705772936344147. Accuracy: 94\n",
      "Iteration: 3000. Loss: 0.12390336394309998. Accuracy: 95\n",
      "Iteration: 3500. Loss: 0.1868055909872055. Accuracy: 95\n",
      "Iteration: 4000. Loss: 0.13565988838672638. Accuracy: 95\n",
      "Iteration: 4500. Loss: 0.12658077478408813. Accuracy: 96\n",
      "Iteration: 5000. Loss: 0.06818234175443649. Accuracy: 96\n",
      "Iteration: 5500. Loss: 0.08663061261177063. Accuracy: 96\n",
      "Iteration: 6000. Loss: 0.09467755258083344. Accuracy: 96\n",
      "Iteration: 6500. Loss: 0.08164642006158829. Accuracy: 96\n",
      "Iteration: 7000. Loss: 0.13865233957767487. Accuracy: 96\n",
      "Iteration: 7500. Loss: 0.126531183719635. Accuracy: 96\n",
      "Iteration: 8000. Loss: 0.08130700886249542. Accuracy: 96\n",
      "Iteration: 8500. Loss: 0.06163925677537918. Accuracy: 97\n",
      "Iteration: 9000. Loss: 0.041212666779756546. Accuracy: 97\n",
      "Iteration: 9500. Loss: 0.08662990480661392. Accuracy: 97\n",
      "Iteration: 10000. Loss: 0.06947990506887436. Accuracy: 97\n",
      "Iteration: 10500. Loss: 0.11462527513504028. Accuracy: 97\n",
      "Iteration: 11000. Loss: 0.04673316329717636. Accuracy: 97\n",
      "Iteration: 11500. Loss: 0.10825664550065994. Accuracy: 97\n",
      "Iteration: 12000. Loss: 0.13501618802547455. Accuracy: 97\n",
      "Iteration: 12500. Loss: 0.050618886947631836. Accuracy: 97\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, 28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = Variable(images.view(-1, 28*28).cuda())\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001D626A22D58>\n",
      "4\n",
      "Parameter containing:\n",
      "tensor([-9.5067e-03,  3.2343e-02,  3.2037e-02, -1.9265e-02, -2.3669e-02,\n",
      "        -1.1958e-02, -9.9688e-03, -8.9702e-03, -2.8975e-02,  4.4591e-03,\n",
      "         4.8244e-03,  1.4223e-03,  7.5565e-03,  3.2924e-05,  1.0543e-02,\n",
      "         1.5221e-02, -9.3783e-03,  2.6155e-03, -3.4561e-03,  2.3895e-02,\n",
      "         1.6179e-02,  2.2199e-02,  9.7457e-03, -2.3617e-02, -1.4926e-02,\n",
      "         1.7569e-02, -2.3757e-02, -3.5613e-02,  3.5169e-02, -1.7436e-02,\n",
      "        -2.0572e-02,  1.7825e-02, -2.4569e-02,  1.7198e-02, -7.1652e-03,\n",
      "         9.4106e-03,  2.0372e-02, -1.1275e-02,  3.2430e-02,  2.3100e-02,\n",
      "        -2.8415e-02,  2.0464e-02,  3.3981e-02,  2.2645e-02,  6.3669e-03,\n",
      "         2.9786e-02,  1.5544e-02,  3.5167e-02, -2.2952e-02,  3.5595e-02,\n",
      "         1.0711e-03, -7.4445e-03, -2.9431e-02,  1.7700e-03, -6.9776e-03,\n",
      "         3.2191e-02,  2.8742e-02,  6.3955e-04, -2.7285e-02,  3.3126e-02,\n",
      "        -2.0060e-02, -6.6094e-04, -8.4831e-03, -1.8274e-02, -3.4219e-02,\n",
      "         2.5151e-02, -2.3615e-02,  1.1979e-02, -1.4529e-02,  3.0232e-02,\n",
      "        -4.6962e-03, -6.6865e-03,  2.7600e-03, -2.1495e-02, -2.0690e-03,\n",
      "         2.6645e-02,  3.1854e-02, -3.1089e-02,  1.6420e-02,  2.6944e-02,\n",
      "        -1.6813e-02, -2.0213e-02, -2.3733e-02,  2.0768e-02, -1.9386e-02,\n",
      "        -3.0257e-02, -1.2504e-02,  8.5966e-03, -2.7824e-02, -2.3717e-02,\n",
      "        -2.7665e-02,  2.1701e-02,  1.0922e-02, -1.8192e-03, -2.6646e-02,\n",
      "        -3.1712e-02, -1.9983e-02,  1.6486e-02, -1.5686e-02,  1.9208e-02],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 13000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        \n",
    "        # Non-linearity \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "print(list(model.parameters())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.49764227867126465. Accuracy: 91\n",
      "Iteration: 1000. Loss: 0.34558406472206116. Accuracy: 92\n",
      "Iteration: 1500. Loss: 0.18043696880340576. Accuracy: 93\n",
      "Iteration: 2000. Loss: 0.14796826243400574. Accuracy: 94\n",
      "Iteration: 2500. Loss: 0.18515442311763763. Accuracy: 95\n",
      "Iteration: 3000. Loss: 0.24979309737682343. Accuracy: 95\n",
      "Iteration: 3500. Loss: 0.14210090041160583. Accuracy: 96\n",
      "Iteration: 4000. Loss: 0.06268902868032455. Accuracy: 96\n",
      "Iteration: 4500. Loss: 0.06783333420753479. Accuracy: 96\n",
      "Iteration: 5000. Loss: 0.0839662253856659. Accuracy: 96\n",
      "Iteration: 5500. Loss: 0.08378181606531143. Accuracy: 97\n",
      "Iteration: 6000. Loss: 0.15154466032981873. Accuracy: 97\n",
      "Iteration: 6500. Loss: 0.07049443572759628. Accuracy: 97\n",
      "Iteration: 7000. Loss: 0.05954616144299507. Accuracy: 97\n",
      "Iteration: 7500. Loss: 0.025450147688388824. Accuracy: 97\n",
      "Iteration: 8000. Loss: 0.03571431338787079. Accuracy: 97\n",
      "Iteration: 8500. Loss: 0.1116565614938736. Accuracy: 97\n",
      "Iteration: 9000. Loss: 0.05823264643549919. Accuracy: 97\n",
      "Iteration: 9500. Loss: 0.06575094908475876. Accuracy: 97\n",
      "Iteration: 10000. Loss: 0.02100648730993271. Accuracy: 97\n",
      "Iteration: 10500. Loss: 0.03195687383413315. Accuracy: 97\n",
      "Iteration: 11000. Loss: 0.09065715968608856. Accuracy: 97\n",
      "Iteration: 11500. Loss: 0.027772674337029457. Accuracy: 97\n",
      "Iteration: 12000. Loss: 0.025303883478045464. Accuracy: 97\n",
      "Iteration: 12500. Loss: 0.03488897159695625. Accuracy: 97\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, 28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = Variable(images.view(-1, 28*28).cuda())\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.15162785351276398. Accuracy: 89\n",
      "Iteration: 1000. Loss: 0.2101718932390213. Accuracy: 93\n",
      "Iteration: 1500. Loss: 0.1529603749513626. Accuracy: 95\n",
      "Iteration: 2000. Loss: 0.20929856598377228. Accuracy: 95\n",
      "Iteration: 2500. Loss: 0.12695719301700592. Accuracy: 96\n",
      "Iteration: 3000. Loss: 0.10877981036901474. Accuracy: 96\n",
      "Iteration: 3500. Loss: 0.0709371268749237. Accuracy: 96\n",
      "Iteration: 4000. Loss: 0.09012982249259949. Accuracy: 96\n",
      "Iteration: 4500. Loss: 0.07318182289600372. Accuracy: 96\n",
      "Iteration: 5000. Loss: 0.028534861281514168. Accuracy: 97\n",
      "Iteration: 5500. Loss: 0.12468843162059784. Accuracy: 97\n",
      "Iteration: 6000. Loss: 0.16371086239814758. Accuracy: 97\n",
      "Iteration: 6500. Loss: 0.05104072391986847. Accuracy: 97\n",
      "Iteration: 7000. Loss: 0.16311556100845337. Accuracy: 97\n",
      "Iteration: 7500. Loss: 0.01565774902701378. Accuracy: 97\n",
      "Iteration: 8000. Loss: 0.019158992916345596. Accuracy: 97\n",
      "Iteration: 8500. Loss: 0.012381171807646751. Accuracy: 97\n",
      "Iteration: 9000. Loss: 0.10265588760375977. Accuracy: 97\n",
      "Iteration: 9500. Loss: 0.06416170299053192. Accuracy: 97\n",
      "Iteration: 10000. Loss: 0.0547325424849987. Accuracy: 97\n",
      "Iteration: 10500. Loss: 0.0006548118544742465. Accuracy: 97\n",
      "Iteration: 11000. Loss: 0.05761303752660751. Accuracy: 97\n",
      "Iteration: 11500. Loss: 0.001674756989814341. Accuracy: 97\n",
      "Iteration: 12000. Loss: 0.06316056847572327. Accuracy: 97\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 50\n",
    "n_iters = 13000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Linear function 3: 100 --> 100\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # Linear function 4 (readout): 100 --> 10\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Linear function 1\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity 1\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Linear function 2\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        # Linear function 2\n",
    "        out = self.fc3(out)\n",
    "        # Non-linearity 2\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        # Linear function 4 (readout)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, 28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                images = Variable(images.view(-1, 28*28).cuda())\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- Logistic regression problems for non-linear functions representation\n",
    " - Cannot represent non-linear functions\n",
    "   - $y = 4x_i + 3 x_2^2 + 3x_3^3$\n",
    "   - $y = x_i * x_2$\n",
    "- Introduced Non-linearity to logistic regression to form a neural network\n",
    "- Types of non-linearity\n",
    " - Sigmoid\n",
    " - Tanh\n",
    " - ReLu\n",
    "- Feedforward Neural Netowrk Models\n",
    " - Model A:  1 hidden layer (sigmoid activation)\n",
    " - Model B: 1 hidden layer (tanh activation)\n",
    " - Model C: 1 hidden layer (ReLU activation)\n",
    " - Model D: 2 hidden layers (ReLU activation)\n",
    " - Model E: 3 hidden layers (ReLU activation)\n",
    "- Models Variation in code\n",
    " - Modifying only step 3\n",
    "- Ways to expand models capacity\n",
    " - More non-linear activation units (neurons)\n",
    " - More hidden layers\n",
    "- Cons of Expanding capacity\n",
    " - Need more data\n",
    " - Does not necessarily mean higher accuracy\n",
    "- GPU Code\n",
    " - 2 things on GPU\n",
    "    - model\n",
    "    - variables\n",
    " - Modifying only step 4 and step 7\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
