{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convolutional Neural Network \n",
    "\n",
    "## 1. About convoutional Neural Network\n",
    "\n",
    "### Basic convolutional neural network\n",
    "- additional **convolution** and **pooling** layers **before** feedforward neural network\n",
    "- layer with **linear function and non-linearity** (the **hidden layer**) is also called  **fully connected layer**\n",
    "\n",
    "### One convolutional layer (gray scale image): high level view\n",
    "You select a filter or kernel. This is a sub matrix, usualy 3x3 or 5x5 (usually an odd number). That will be used to run the convolution. You can imagine that this filter is a spotlight that will be used to inspect the entire input matrix.\n",
    "\n",
    "Whenever you apply your filter/kernel to the matrix at any given point you are essentially multiplying every point in the original matrix that falls in the area of the filter (**the receptive field**) and summing all of them together. Than you store this number in a new output matrix. This output matrix is called **the feature map**.\n",
    "\n",
    "Once that is done, you move the filter to a new spot in the input matrix. How many elements you move from one spot to the other is called **stride** and it is usually 2 or 3.\n",
    "\n",
    "The same multiplication and sum operations are repeated and the value is stored in the output matrix at the adjecent point of the first output.\n",
    "\n",
    "\n",
    "You can have kernels of multiple sizes. And for every kernel you can \"inspect\" an entire image and output a different feature map. Indeed as many feature maps as kernels you want to apply\n",
    "\n",
    "#### What happens when we apply the filter?\n",
    "The filter usually describes a shape, an edge, a relationship, a line, a dot, something. Usually in the form of values between 0 and 1 [or -1 and 1]. Because of that. The filter will respond the maximum when the input is exactly the same as the the filter. \n",
    "\n",
    "If the element in the input matrix correspond to a 1 in the same element of the filter. The output will be the same as the value in the input matrix. If it corresponds to a 0 it does not affects the output value. if it is a -1 it penalizes the value in the output matrix.\n",
    "\n",
    "### Three convolutional layer (color image)\n",
    "The only difference is that your kernel must have the same depth as the input tensor.\n",
    "\n",
    "### Multiple convolutional layers\n",
    "Progressive convolutions gradually abstracts the what from where. \n",
    "After you finish passing through a series of convolutional layers. you connect it to a fully connected layer that will finally output a decision regarding the input (softmax).\n",
    "\n",
    "### Pooling and down sampling\n",
    "The pooling layer follows the convolution layer. The goal in using a pooling layer is to down sample the convolutional layer (and reduce the size of its representation).\n",
    "\n",
    "The most common types of pooling are\n",
    "- max pooling\n",
    "- average pooling\n",
    "\n",
    "In pooling, as in convolution, you also have a kernel (usually 2x2) that you will use to inspect the whole featuremap outputed from the previous convolution operation. At any inspection point, you are going to see all the elements that falls into the pooling kernel and get the maximum value or the average, depending on the kind of pooling you are doing. And store it in the output matrix at a correspondent element.\n",
    "\n",
    "### Padding\n",
    "It affects whether the output of the pooling has the same size or smaller than the input feature map.\n",
    "formula for the size of the matrix after convolution\n",
    "$$O = \\frac{W-K+2p}{S}+1$$\n",
    "Where:\n",
    "- O : output height/length\n",
    "- W : input height / length\n",
    "- K : filter size (kernel size)\n",
    "- P : same padding (non-zero)\n",
    "   - P = $\\frac{K-1}{2} = \\frac{5-1}{2} = 2$\n",
    "- S : stride\n",
    "\n",
    "**Zero padding** is also called **Valid padding**. The output matrix will be smaller than the input feature mab by the size of the pooling kernel rounded to the lowest even number. example: if you have a input feature map of 7x7 and a pooling kernel of 3x3 the output matrix will be 7-2 = 5x5\n",
    "\n",
    "**Same padding**. This is when you want the output matrix to have the same size as the input feature map. To do this you must add elements to the border of the matrix. in each border you must add the size of the kernel rounded to the lowest closest even number divided by 2. Example: if you pooling kernel is 7x7, the lowest even number is 6, divided by 2 is 3, so in every border you should add 3 elements.\n",
    "$$ Padding = \\frac{Kernel -1}{1} $$\n",
    "\n",
    "The padding can be composed of just zeros or copy of the elements close to the corner or the mirror image of the pixels close to the corner.\n",
    "## Building a convolutional neural network with pytorch\n",
    "### Model A:\n",
    "- 2 convoluntional Layers\n",
    "   - Same padding (same output size)\n",
    "- 2 Max pooling layers\n",
    "- 1 fully connected layer\n",
    "\n",
    "### Steps\n",
    "1. Load Dataset\n",
    "2. Make Dataset iterable\n",
    "3. Make model class\n",
    "4. Instantiate the model\n",
    "5. Instantiate the loss class\n",
    "6. Instantiate the optimizer\n",
    "7. Train\n",
    "8. Measure accuracy\n",
    "9. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a convolutional neural network with pytorch\n",
    "\"\"\"\n",
    "0. Import libraries\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Load Dataset\n",
    "\"\"\"\n",
    "\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                           train = True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())\n",
    "print(train_dataset.train_labels.size())\n",
    "print(test_dataset.test_data.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Make the dataset iterable\n",
    "\n",
    "\"\"\"\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                     batch_size = batch_size,\n",
    "                                     shuffle = True)\n",
    "\n",
    "test_loader =  torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3. Create a Model\n",
    "\"\"\"\n",
    "\n",
    "class CNN_ModelA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ModelA, self).__init__()\n",
    "        # Because in CNNs it is more complicated to define the input and output dimension\n",
    "        # the input and output dimensions are going to be inserted manually\n",
    "        \n",
    "        # 1st Convolution\n",
    "        self.cnn1 = nn.Conv2d(in_channels = 1,   # channels are the number of layers 1- gray 3- color\n",
    "                              out_channels = 16, # number of layers in the feature maps, 16 features\n",
    "                              kernel_size=5,     # size of the filter\n",
    "                              stride=1,          # value by which the filter will walk\n",
    "                              padding=2)         # padding to prevent the featuremap to be smaller.\n",
    "        \n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 1st Pooling: Max pooling\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # 2nd Convolution\n",
    "        self.cnn2 = nn.Conv2d(in_channels = 16, \n",
    "                              out_channels = 32, \n",
    "                              kernel_size=5, \n",
    "                              stride=1, \n",
    "                              padding=2)\n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # 2nd Pooling: Max pooling\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*7*7,10) # 7 is because the original image has 28 x 28 pixels and it passes by 2 max poolings\n",
    "                                        # with kernels with size 2. So 28 / (2*2) = 7\n",
    "                                        # 32 is the number of featuremaps as inputs\n",
    "                                        # 10 is the number of possible classes\n",
    "\n",
    "    def forward(self,x): \n",
    "        # Conv Layer 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Conv layer 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # To fit into the linear function you need to flatten the 3D tensor of feature maps into a 1D tensor\n",
    "        # Original size : (100,32,7,7)\n",
    "        # out.size(0) = 100\n",
    "        # new outsize = (100,32*7*7)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        # Linear function(readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. Instantiate the model class\n",
    "\"\"\"\n",
    "\n",
    "model = CNN_ModelA()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. Instantiate the Loss class\n",
    "\"\"\"\n",
    "# Convolution Neural Network: Cross Entropy Loss\n",
    "    # Feedforward Neural Network : Cross entropy Loss\n",
    "    # Logistic Regression : Cross entropy loss\n",
    "    # Linear Regression: MSE\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Instantiate Optimizer Class\n",
    "- simplified equation\n",
    "    - $\\theta = \\theta- \\alpha . \\delta_\\theta$ \n",
    "    - where\n",
    "        - $\\theta$ : parameters (our variables)\n",
    "        - $\\alpha$ : learning rate (our variables)\n",
    "        - $\\delta_\\theta$ : parameters gradient\n",
    "    - even simplier equation\n",
    "        - parameters = parameters - learning_rate * parameters_gradiente\n",
    "        - at every iteration, we update our models parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. Instantiate the optimizer class\n",
    "\"\"\"\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000002226554C990>\n",
      "6\n",
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# What is inside the model\n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters())))\n",
    "print(list(model.parameters())[0].size()) # Conv1 : 16 kernels\n",
    "print(list(model.parameters())[1].size()) # Conv1 Bias: 16 kernels\n",
    "\n",
    "print(list(model.parameters())[2].size()) # Conv2 Bias: 32 Kernels with depth 16\n",
    "print(list(model.parameters())[3].size()) # Conv2 Bias: 32 kernels\n",
    "\n",
    "print(list(model.parameters())[4].size()) # Fully connected layer 1\n",
    "print(list(model.parameters())[5].size()) # Fully connected bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "- Process\n",
    "    1. Convert inputs/ labels to variables\n",
    "        - CNN input: (1,28,28) - the only difference from FFNN is that a CNN can receive a 2D tensor as input\n",
    "        - Feedforward NN Input: (1,28*28)\n",
    "    2. Clear gradient buffers\n",
    "    3. Get output given inputs\n",
    "    4. Get loss\n",
    "    5. Get Gradients with respect to parameters\n",
    "    6. Update parameters using gradients\n",
    "        -  parameters = parameters - learning_rate * parameters_gradiente\n",
    "    7. REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss:0.04247228056192398. Accuracy: 98\n",
      "Iteration: 1000. Loss:0.12507490813732147. Accuracy: 98\n",
      "Iteration: 1500. Loss:0.10888931155204773. Accuracy: 98\n",
      "Iteration: 2000. Loss:0.025883041322231293. Accuracy: 98\n",
      "Iteration: 2500. Loss:0.053134769201278687. Accuracy: 98\n",
      "Iteration: 3000. Loss:0.021015744656324387. Accuracy: 98\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        # Accuracy test\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.cuda())\n",
    "                else:\n",
    "                    images = Variable(images)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                \n",
    "                total += labels.size(0)\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss:{}. Accuracy: {}'.format(iter,loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN Model B\n",
    "- using average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss:0.6524097919464111. Accuracy: 86\n",
      "Iteration: 1000. Loss:0.6030823588371277. Accuracy: 89\n",
      "Iteration: 1500. Loss:0.2930809259414673. Accuracy: 89\n",
      "Iteration: 2000. Loss:0.29460909962654114. Accuracy: 91\n",
      "Iteration: 2500. Loss:0.28996703028678894. Accuracy: 92\n",
      "Iteration: 3000. Loss:0.2284603714942932. Accuracy: 93\n"
     ]
    }
   ],
   "source": [
    "## Building a convolutional neural network with pytorch\n",
    "\"\"\"\n",
    "0. Import libraries\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\"\"\"\n",
    "1. Load Dataset\n",
    "\"\"\"\n",
    "\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                           train = True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "\"\"\"\n",
    "2. Make the dataset iterable\n",
    "\n",
    "\"\"\"\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                     batch_size = batch_size,\n",
    "                                     shuffle = True)\n",
    "\n",
    "test_loader =  torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle = False)\n",
    "\n",
    "\"\"\"\n",
    "3. Create a Model\n",
    "\"\"\"\n",
    "\n",
    "class CNN_ModelB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ModelB, self).__init__()\n",
    "        # Because in CNNs it is more complicated to define the input and output dimension\n",
    "        # the input and output dimensions are going to be inserted manually\n",
    "        \n",
    "        # 1st Convolution\n",
    "        self.cnn1 = nn.Conv2d(in_channels = 1,   # channels are the number of layers 1- gray 3- color\n",
    "                              out_channels = 16, # number of layers in the feature maps, 16 features\n",
    "                              kernel_size=5,     # size of the filter\n",
    "                              stride=1,          # value by which the filter will walk\n",
    "                              padding=2)         # padding to prevent the featuremap to be smaller.\n",
    "        \n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 1st Pooling: Average pooling\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # 2nd Convolution\n",
    "        self.cnn2 = nn.Conv2d(in_channels = 16, \n",
    "                              out_channels = 32, \n",
    "                              kernel_size=5, \n",
    "                              stride=1, \n",
    "                              padding=2)\n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # 2nd Pooling: Average pooling\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*7*7,10) # 7 is because the original image has 28 x 28 pixels and it passes by 2 max poolings\n",
    "                                        # with kernels with size 2. So 28 / (2*2) = 7\n",
    "                                        # 32 is the number of featuremaps as inputs\n",
    "                                        # 10 is the number of possible classes\n",
    "\n",
    "    def forward(self,x): \n",
    "        # Conv Layer 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.avgpool1(out)\n",
    "        \n",
    "        # Conv layer 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.avgpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # To fit into the linear function you need to flatten the 3D tensor of feature maps into a 1D tensor\n",
    "        # Original size : (100,32,7,7)\n",
    "        # out.size(0) = 100\n",
    "        # new outsize = (100,32*7*7)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        # Linear function(readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\"\"\"\n",
    "4. Instantiate the model class\n",
    "\"\"\"\n",
    "\n",
    "model = CNN_ModelB()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "\"\"\"\n",
    "5. Instantiate the Loss class\n",
    "\"\"\"\n",
    "# Convolution Neural Network: Cross Entropy Loss\n",
    "    # Feedforward Neural Network : Cross entropy Loss\n",
    "    # Logistic Regression : Cross entropy loss\n",
    "    # Linear Regression: MSE\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\"\"\"\n",
    "6. Instantiate the optimizer class\n",
    "\"\"\"\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "7. TRain the model\n",
    "\"\"\"\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        # Accuracy test\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.cuda())\n",
    "                else:\n",
    "                    images = Variable(images)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                \n",
    "                total += labels.size(0)\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss:{}. Accuracy: {}'.format(iter,loss.data, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN Model C\n",
    "- uses max pooling\n",
    "- uses valid padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss:0.15751191973686218. Accuracy: 92\n",
      "Iteration: 1000. Loss:0.11110392212867737. Accuracy: 95\n",
      "Iteration: 1500. Loss:0.2289888560771942. Accuracy: 96\n",
      "Iteration: 2000. Loss:0.1407839059829712. Accuracy: 96\n",
      "Iteration: 2500. Loss:0.0230003260076046. Accuracy: 97\n",
      "Iteration: 3000. Loss:0.03644980862736702. Accuracy: 97\n"
     ]
    }
   ],
   "source": [
    "## Building a convolutional neural network with pytorch\n",
    "\"\"\"\n",
    "0. Import libraries\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\"\"\"\n",
    "1. Load Dataset\n",
    "\"\"\"\n",
    "\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                           train = True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "\"\"\"\n",
    "2. Make the dataset iterable\n",
    "\n",
    "\"\"\"\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                     batch_size = batch_size,\n",
    "                                     shuffle = True)\n",
    "\n",
    "test_loader =  torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle = False)\n",
    "\n",
    "\"\"\"\n",
    "3. Create a Model\n",
    "\"\"\"\n",
    "\n",
    "class CNN_ModelC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_ModelC, self).__init__()\n",
    "        # Because in CNNs it is more complicated to define the input and output dimension\n",
    "        # the input and output dimensions are going to be inserted manually\n",
    "        \n",
    "        # 1st Convolution\n",
    "        self.cnn1 = nn.Conv2d(in_channels = 1,   # channels are the number of layers 1- gray 3- color\n",
    "                              out_channels = 16, # number of layers in the feature maps, 16 features\n",
    "                              kernel_size=5,     # size of the filter\n",
    "                              stride=1,          # value by which the filter will walk\n",
    "                              padding=0)         # padding to prevent the featuremap to be smaller.\n",
    "        \n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 1st Pooling: Average pooling\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # 2nd Convolution\n",
    "        self.cnn2 = nn.Conv2d(in_channels = 16, \n",
    "                              out_channels = 32, \n",
    "                              kernel_size=5, \n",
    "                              stride=1, \n",
    "                              padding=0)\n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # 2nd Pooling: Average pooling\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(32*4*4,10) # 7 is because the original image has 28 x 28 pixels and it passes by 2 max poolings\n",
    "                                        # with kernels with size 2. So 28 / (2*2) = 7\n",
    "                                        # 32 is the number of featuremaps as inputs\n",
    "                                        # 10 is the number of possible classes\n",
    "\n",
    "    def forward(self,x): \n",
    "        # Conv Layer 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.avgpool1(out)\n",
    "        \n",
    "        # Conv layer 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.avgpool2(out)\n",
    "        \n",
    "        # Resize\n",
    "        # To fit into the linear function you need to flatten the 3D tensor of feature maps into a 1D tensor\n",
    "        # Original size : (100,32,7,7)\n",
    "        # out.size(0) = 100\n",
    "        # new outsize = (100,32*7*7)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        # Linear function(readout)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\"\"\"\n",
    "4. Instantiate the model class\n",
    "\"\"\"\n",
    "\n",
    "model = CNN_ModelC()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "\"\"\"\n",
    "5. Instantiate the Loss class\n",
    "\"\"\"\n",
    "# Convolution Neural Network: Cross Entropy Loss\n",
    "    # Feedforward Neural Network : Cross entropy Loss\n",
    "    # Logistic Regression : Cross entropy loss\n",
    "    # Linear Regression: MSE\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\"\"\"\n",
    "6. Instantiate the optimizer class\n",
    "\"\"\"\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "7. TRain the model\n",
    "\"\"\"\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        # Accuracy test\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.cuda())\n",
    "                else:\n",
    "                    images = Variable(images)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                \n",
    "                total += labels.size(0)\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss:{}. Accuracy: {}'.format(iter,loss.data, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding CNNs\n",
    "There are 3 ways to expand a convolutional neural network\n",
    "1. More convolutional layers\n",
    "2. Less agressive downsampling\n",
    "    - smaller kernel size for pooling (gradually downsampling)\n",
    "3. More fully connected layers\n",
    "\n",
    "Cons:\n",
    "1. It needs a larger dataset\n",
    "    - Curse of dimensionality\n",
    "2. Does not necessarily mean higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Transition from **feedforward neural networ**\n",
    "- addition of convolutiona+relu+pooling layers before the linear layers\n",
    "- one convolutional layer basics\n",
    "- One pooling layer basics\n",
    "    - Max pooling\n",
    "    - Average pooling\n",
    "- Padding\n",
    "- **Output Dimension** Calculations and Examples\n",
    "    - $ O = \\frac{W.K+2P}{S}+1$\n",
    "- Convolutional Neural Networks\n",
    "    - Model A: \n",
    "        - 2 Conv + 2 Max pool +1 FC\n",
    "        - Same Padding\n",
    "    - Model B: \n",
    "        - 2 Conv + 2 Average pool +1 FC\n",
    "        - Same Padding\n",
    "    - Model C: \n",
    "        - 2 Conv + 2 Max pool +1 FC\n",
    "        - Valid Padding\n",
    "- Model variation in Code\n",
    "    - Modify only Step 3 in the model\n",
    "    - Special attention to the size of the input to the linear layer\n",
    "- Ways to Expand Models capacity\n",
    "    - More convolutions\n",
    "    - Gradual pooling\n",
    "    - More fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
